1
00:00:00,000 --> 00:00:06,880
Hello everyone, my name is Zhenyu, thanks for the intro.


2
00:00:06,880 --> 00:00:12,480
I'm a little bit background for myself, I'm a PhD student, second year as a new PhD student


3
00:00:12,480 --> 00:00:15,000
at Stony Brook University.


4
00:00:15,000 --> 00:00:20,600
Today I will be present, our work will be appears in the web conference 2023 which happens


5
00:00:20,600 --> 00:00:23,400
in May.


6
00:00:23,400 --> 00:00:29,320
The work is about video streaming on IPFS, so is IPFS ready for decentralized streaming?


7
00:00:29,320 --> 00:00:35,420
So I will briefly give everyone knows here, knows that IPFS is a decentralized storage


8
00:00:35,420 --> 00:00:39,920
and delivery network, it builds on top to peer-to-peer network structure and uses content


9
00:00:39,920 --> 00:00:45,360
addressing.


10
00:00:45,360 --> 00:00:52,760
And thanks for the probe lab, here's the stats from IPFS and we can see IPFS has gained significant


11
00:00:52,760 --> 00:00:59,440
popularity over the time and it has a lot of apps built around with it, like popular


12
00:00:59,440 --> 00:01:04,960
browsers have native support for IPFS and also such as CDN service Cluffer have supports


13
00:01:04,960 --> 00:01:06,340
for IPFS.


14
00:01:06,340 --> 00:01:08,520
So why streaming on IPFS?


15
00:01:08,520 --> 00:01:14,200
So video is the most popular traffic on the internet and IPFS has a strong robustness


16
00:01:14,200 --> 00:01:20,920
against failure and censorship, so with the gaining popularity we ask can video streaming


17
00:01:20,920 --> 00:01:27,040
utilize the benefits of IPFS to achieve a better playback experience?


18
00:01:27,040 --> 00:01:31,000
Well obvious we're not the first people thought about the idea, so Dtube exists.


19
00:01:31,000 --> 00:01:38,600
Dtube is a video streaming service with IPFS that utilize IPFS as its video storage system.


20
00:01:38,600 --> 00:01:44,280
It has seen quite a bit of popularity with one upload per minute and four million monthly


21
00:01:44,280 --> 00:01:45,960
visitors.


22
00:01:45,960 --> 00:01:47,840
That's from the stats from Dtube.


23
00:01:47,840 --> 00:01:53,920
However upon our study there's a big problem with Dtube, is that Dtube uses its own private


24
00:01:53,920 --> 00:01:59,920
cluster which means that the video on Dtube cannot be retrieved from the public IPFS network


25
00:01:59,920 --> 00:02:05,240
which I think is defeat the purpose of IPFS where everyone can access the content and


26
00:02:05,240 --> 00:02:08,840
can participate the network to share the content.


27
00:02:08,840 --> 00:02:13,140
So we don't know if truly decentralized video streaming is possible on IPFS.


28
00:02:13,140 --> 00:02:18,200
To answer the question we conduct first conduct a measurement study on how video performs


29
00:02:18,200 --> 00:02:23,800
IPFS currently, then we introduce Telescope, a system that can improve video streaming


30
00:02:23,800 --> 00:02:30,660
on IPFS and then we evaluate Telescope IPFS network.


31
00:02:30,660 --> 00:02:36,680
So for the measurement setup we collect videos from IPFS search.


32
00:02:36,680 --> 00:02:41,840
As we know IPFS use content address which means that the hash of content is identifying


33
00:02:41,840 --> 00:02:42,840
the network.


34
00:02:42,840 --> 00:02:47,200
There is no human readable labels associated with the content.


35
00:02:47,200 --> 00:02:53,040
So therefore we cannot just simply Google videos IPFS and then retrieve the content.


36
00:02:53,040 --> 00:02:55,160
To do this we use IPFS search.


37
00:02:55,160 --> 00:03:00,960
IPFS search solves the problem with content addressing by deploying multiple instances


38
00:03:00,960 --> 00:03:06,240
in the network and sniff around the content that was being shared around the networks


39
00:03:06,240 --> 00:03:09,720
and then they will download the file and index them.


40
00:03:09,720 --> 00:03:16,200
So we just ask the videos CID from them and they will give us the video CID.


41
00:03:16,200 --> 00:03:21,160
For each video CID we contact the IPFS network and try to retrieve the video.


42
00:03:21,160 --> 00:03:27,640
Upon the retrieval we will measure the video resolution, video stall and RTT to the provider.


43
00:03:27,640 --> 00:03:32,440
And also we will try to retrieve the video under different network conditions.


44
00:03:32,440 --> 00:03:36,760
So we collect our data from September 1st to October 4th of 2022.


45
00:03:36,760 --> 00:03:42,440
We retrieved over 39,000 unique CIDs from IPFS search and we were able to successfully


46
00:03:42,440 --> 00:03:46,480
download over 28,000 of them.


47
00:03:46,480 --> 00:03:52,560
So our goal is to try to understand video streaming and performance in IPFS.


48
00:03:52,560 --> 00:03:56,260
Therefore we in fact see a lot of videos being shared around the networks.


49
00:03:56,260 --> 00:04:01,000
So let's see some results to show how poor video streaming is in IPFS.


50
00:04:01,000 --> 00:04:07,080
So first we observe that we notice that video experience extremely high stall under poorer


51
00:04:07,080 --> 00:04:08,080
network.


52
00:04:08,080 --> 00:04:14,840
As this figure shows for 8 Mbps 90% of video we stream has experienced stall and for 25


53
00:04:14,840 --> 00:04:17,720
Mbps half of them experienced stall.


54
00:04:17,720 --> 00:04:23,540
More importantly for the video that stall the median stall rate for 8 Mbps is 9.


55
00:04:23,540 --> 00:04:28,480
This means that the stream of video, the time to stream the video itself takes 10 times


56
00:04:28,480 --> 00:04:33,600
as the original duration of the video which is very, very bad.


57
00:04:33,600 --> 00:04:39,360
Then for 25 Mbps it's slightly better but it's still high with the 5.


58
00:04:39,360 --> 00:04:40,360
So what's the reason?


59
00:04:40,360 --> 00:04:44,740
So one reason we think is from the high RTT for the video providers.


60
00:04:44,740 --> 00:04:49,760
As this figure shows the median is around 67 milliseconds and the 90th percentile was


61
00:04:49,760 --> 00:04:52,760
around 100 milliseconds.


62
00:04:52,760 --> 00:04:54,480
So why the video is so high?


63
00:04:54,480 --> 00:04:58,440
So one of the reasons we just mentioned before is probably because the high RTT for the video


64
00:04:58,440 --> 00:04:59,640
provider.


65
00:04:59,640 --> 00:05:03,880
This can be partitionally solved by caching which is closer to the user.


66
00:05:03,880 --> 00:05:09,400
The second more important reason is the single encoding of the video.


67
00:05:09,400 --> 00:05:12,920
Video streaming cannot adapt to the quality according to the network condition.


68
00:05:12,920 --> 00:05:18,520
So let's say you have a 4K video and the user has 8 Mbps of network condition it will try


69
00:05:18,520 --> 00:05:24,920
to stream that high 4K video and then causing the user to have stalls.


70
00:05:24,920 --> 00:05:30,200
So one natural approach to streaming under that network is ABR.


71
00:05:30,200 --> 00:05:35,280
I will briefly talk about how ABR works and why it doesn't work with FPFS.


72
00:05:35,280 --> 00:05:40,520
So adaptive bit rate streaming works by first it breaks the video into different segments


73
00:05:40,520 --> 00:05:42,840
as shown here.


74
00:05:42,840 --> 00:05:48,160
Then for each segment it will encode them into different quality from high to low.


75
00:05:48,160 --> 00:05:53,600
Then all these video segments will be stored into a server and the server will pass down


76
00:05:53,600 --> 00:05:55,560
a manifest file to a client.


77
00:05:55,560 --> 00:06:01,480
A manifest file essentially is a list of bandwidth requirements for retrieving that quality of


78
00:06:01,480 --> 00:06:03,320
content.


79
00:06:03,320 --> 00:06:07,800
Then the client will estimate its network throughput from the server to the client.


80
00:06:07,800 --> 00:06:14,360
Based on that throughput you will pick the best affordable quality to stream.


81
00:06:14,360 --> 00:06:17,800
So now let's see how ABR will work with FPFS.


82
00:06:17,800 --> 00:06:19,320
So everything will be the same.


83
00:06:19,320 --> 00:06:21,200
We have video segments.


84
00:06:21,200 --> 00:06:22,200
We have a user.


85
00:06:22,200 --> 00:06:23,320
We have a manifest file.


86
00:06:23,320 --> 00:06:29,000
And instead of storing all the segments into a server, now this can be stored into a FPFS


87
00:06:29,000 --> 00:06:30,000
network.


88
00:06:30,000 --> 00:06:33,160
As many of you guys know, maybe know the issue here.


89
00:06:33,160 --> 00:06:38,280
So now the video can be stored into different instances on a FPFS network and also may be


90
00:06:38,280 --> 00:06:42,140
cached in a cache node that was being cached.


91
00:06:42,140 --> 00:06:46,520
So then the ABR client will try to estimate the network throughput from the client to


92
00:06:46,520 --> 00:06:49,880
the FPFS network.


93
00:06:49,880 --> 00:06:54,000
Our ABR client cannot estimate the network throughput correctly because video can be


94
00:06:54,000 --> 00:07:00,280
retrieved from the cache or different instances from the FPFS network.


95
00:07:00,280 --> 00:07:05,040
Now to see this inconsistent throughput, to see the effect of this inaccurate estimated


96
00:07:05,040 --> 00:07:09,720
throughput, we analyze the trace of ABR client's estimated throughput during a playback of


97
00:07:09,720 --> 00:07:11,200
video.


98
00:07:11,200 --> 00:07:19,640
Here we have a blue line which represents the client's estimated throughput at the time.


99
00:07:19,640 --> 00:07:24,480
And we have a green line represents the actual throughput from the client to the FPFS network,


100
00:07:24,480 --> 00:07:26,720
which is the provider of the network.


101
00:07:26,720 --> 00:07:30,360
And then we have the orange line, which means the actual throughput from the client to the


102
00:07:30,360 --> 00:07:31,360
gateway.


103
00:07:31,360 --> 00:07:36,880
Here we assume that gateway has some part of cache of the segments.


104
00:07:36,880 --> 00:07:41,200
Now let's see how the ABR client estimates itself.


105
00:07:41,200 --> 00:07:46,600
At the beginning, when the segments are retrieved from the gateway, which has a higher throughput,


106
00:07:46,600 --> 00:07:50,600
the client estimates throughput closer to the orange line, which makes sense.


107
00:07:50,600 --> 00:07:53,200
It was retrieved from the gateway.


108
00:07:53,200 --> 00:07:57,760
And then the following segments are retrieved from the network, which has a significantly


109
00:07:57,760 --> 00:07:59,000
lower throughput.


110
00:07:59,000 --> 00:08:01,280
At the bottom we can see.


111
00:08:01,280 --> 00:08:05,000
But ABR client doesn't know this sudden change of throughput.


112
00:08:05,000 --> 00:08:11,400
It will overestimate its available throughput to be close to the cache.


113
00:08:11,400 --> 00:08:14,080
And then it will pick a high quality to stream.


114
00:08:14,080 --> 00:08:19,400
And then the client will suffer from the bandwidth limitation causing stall.


115
00:08:19,400 --> 00:08:21,480
And the ABR client realizes the issue.


116
00:08:21,480 --> 00:08:23,800
So it throttles back to its estimation.


117
00:08:23,800 --> 00:08:31,480
However, due to the algorithm of computing the estimation, the client still has overestimated


118
00:08:31,480 --> 00:08:37,520
the throughput, which means the cycle of stall and then reduce, stall and then reduce continues


119
00:08:37,520 --> 00:08:43,680
until the segments hit the cache again, which we can see it will bounce back the throughput.


120
00:08:43,680 --> 00:08:50,520
This happened repeatedly throughout the playback and causing a very inconsistent streaming


121
00:08:50,520 --> 00:08:52,560
experience.


122
00:08:52,560 --> 00:08:59,000
So to solve this inconsistent experience, we introduced Telescope.


123
00:08:59,000 --> 00:09:04,480
Telescope works like a proxy between the client and the gateway.


124
00:09:04,480 --> 00:09:09,680
It works normally when ABR client requests a video, it will forward this request to IPFS


125
00:09:09,680 --> 00:09:14,000
gateway and the IPFS gateway will retrieve the content from the network.


126
00:09:14,000 --> 00:09:17,280
Then the IPFS gateway will return back to Telescope.


127
00:09:17,280 --> 00:09:21,240
But Telescope does not directly return to ABR client.


128
00:09:21,240 --> 00:09:27,320
Instead it will update a manifest file and sends that along with the video segments.


129
00:09:27,320 --> 00:09:30,460
So why manifest file, right?


130
00:09:30,460 --> 00:09:36,920
So at this point, we know that ABR client has inaccurate estimation of throughput due


131
00:09:36,920 --> 00:09:43,480
to the segments can come from different network peers or the different from the gateway.


132
00:09:43,480 --> 00:09:50,400
So to help ABR to make the best decision, the natural way to do is to modify the manifest


133
00:09:50,400 --> 00:09:58,840
file such that you will incorporate the throughput information from the cached or uncached.


134
00:09:58,840 --> 00:10:04,520
This way, even the ABR client has inaccurate estimate throughput, it can still make a correct


135
00:10:04,520 --> 00:10:10,320
decision based on the modified MPD file, which is the manifest file.


136
00:10:10,320 --> 00:10:17,000
So to see how CloudScope modifies MPD file, let's first see how the MS file works with


137
00:10:17,000 --> 00:10:19,720
traditional ABR without Telescope.


138
00:10:19,720 --> 00:10:23,660
For this example, we have a segment X, which is five seconds in duration.


139
00:10:23,660 --> 00:10:26,920
It has two quality, quality one and quality two.


140
00:10:26,920 --> 00:10:30,840
So quality one is 10 Mbp and quality two is 15 Mbp.


141
00:10:30,840 --> 00:10:35,760
And let's assume the quality one is uncached and quality two is cached.


142
00:10:35,760 --> 00:10:41,160
Now the generated manifest file will say that quality one need two Mbps of bandwidth and


143
00:10:41,160 --> 00:10:43,420
quality two need three Mbps.


144
00:10:43,420 --> 00:10:47,440
This can be easily calculated by the size of the quality divided by the duration of


145
00:10:47,440 --> 00:10:48,760
the segments.


146
00:10:48,760 --> 00:10:52,200
In this case, it's 10 divided by five and 15 divided by five.


147
00:10:52,200 --> 00:10:57,360
Now this manifest file will pass to ABR client and the client estimate its throughput is


148
00:10:57,360 --> 00:10:58,360
two Mbps.


149
00:10:58,360 --> 00:11:04,000
Therefore, it will pick quality one as quality two requires three Mbps, which is higher than


150
00:11:04,000 --> 00:11:06,320
its estimation.


151
00:11:06,320 --> 00:11:15,040
However, we know that quality two is cached and then the cache throughput is four Mbps.


152
00:11:15,040 --> 00:11:18,260
And then it required a bandwidth of three Mbps.


153
00:11:18,260 --> 00:11:24,800
So that cache segment is well satisfied and is a better option because it has higher quality.


154
00:11:24,800 --> 00:11:31,440
However, ABR will not do that because the poor estimation we mentioned earlier.


155
00:11:31,440 --> 00:11:36,600
Now let's see how Telescope will help this.


156
00:11:36,600 --> 00:11:43,720
We have the same example where quality one is uncached and quality two is cached.


157
00:11:43,720 --> 00:11:48,360
Now Telescope, instead of passing the manifest file directly to the client, now Telescope


158
00:11:48,360 --> 00:11:53,100
will use the cached information and throughput information to update the manifest file.


159
00:11:53,100 --> 00:11:54,600
So let's look at quality one.


160
00:11:54,600 --> 00:11:59,760
We know quality one is uncached and we know the throughput of uncached is one Mbps.


161
00:11:59,760 --> 00:12:02,960
And then the client estimates the throughput is two Mbps.


162
00:12:02,960 --> 00:12:09,560
So therefore, we know that the client is overestimating the throughput by one Mbps.


163
00:12:09,560 --> 00:12:16,040
Therefore we're adding one Mbps to the original manifest file to compensate that overestimation.


164
00:12:16,040 --> 00:12:18,400
For quality two, it works similarly.


165
00:12:18,400 --> 00:12:19,880
We know it's cached.


166
00:12:19,880 --> 00:12:25,000
The cached segment is four Mbps and the client estimation is two Mbps.


167
00:12:25,000 --> 00:12:29,560
So in this case, we know that ABR client underestimated by two Mbps.


168
00:12:29,560 --> 00:12:36,120
To compensate this underestimation, we reduce the two Mbps from the original manifest file.


169
00:12:36,120 --> 00:12:40,400
Now it will be one Mbps.


170
00:12:40,400 --> 00:12:44,040
Now Telescope forward-backs this to ABR client.


171
00:12:44,040 --> 00:12:50,080
Now ABR client knows it has two Mbps and then the quality two only need one Mbps.


172
00:12:50,080 --> 00:12:53,960
So it will pick the better choice, which is quality two.


173
00:12:53,960 --> 00:12:59,040
So Telescope directly works by first taking the original manifest file and it will take


174
00:12:59,040 --> 00:13:02,600
the cached information from the gateway.


175
00:13:02,600 --> 00:13:08,040
And then the throughput information, which the Telescope itself estimated.


176
00:13:08,040 --> 00:13:12,320
And then it will compute and compensate the inaccurate estimation to the updated manifest


177
00:13:12,320 --> 00:13:17,200
file and it helps the client to make a better decision.


178
00:13:17,200 --> 00:13:21,920
Now let's evaluate Telescope on the IPFS network.


179
00:13:21,920 --> 00:13:29,280
For the measurement setup, we have client, Telescope, IPFS gateway, and IPFS networks.


180
00:13:29,280 --> 00:13:36,040
We deploy our videos into five IPFS instance across the globe, as shown here.


181
00:13:36,040 --> 00:13:41,720
And then we'll also set up the cache hit rate of 80% and 60%.


182
00:13:41,720 --> 00:13:47,720
A cache hit rate means that we prefetch the video from IPFS gateway such that the video


183
00:13:47,720 --> 00:13:51,480
will be cached on the gateway.


184
00:13:51,480 --> 00:13:56,860
Then we will retrieve the video from Telescope, as the figure shows.


185
00:13:56,860 --> 00:14:04,040
The Telescope and the client are co-located together at the deployed northeast of US.


186
00:14:04,040 --> 00:14:08,280
Now let's see the metric we use to evaluate Telescope.


187
00:14:08,280 --> 00:14:16,560
Just for the baseline, we compare Telescope streaming performance over IPFS, which is


188
00:14:16,560 --> 00:14:19,320
direct streaming IPFS without anything.


189
00:14:19,320 --> 00:14:24,520
We also compare it to traditional ABR and also which compare different algorithm ABR.


190
00:14:24,520 --> 00:14:29,920
So ABR, as we mentioned before, it will estimate its throughput and make a decision.


191
00:14:29,920 --> 00:14:32,040
And different algorithm can do differently.


192
00:14:32,040 --> 00:14:38,600
For ABR BOLA, it's a buffer-based algorithm, which means that it will not care about the


193
00:14:38,600 --> 00:14:39,600
estimate throughput.


194
00:14:39,600 --> 00:14:43,480
Instead, it will care about the buffer of the video.


195
00:14:43,480 --> 00:14:51,400
For ABR Dynamic, I think it will use a combination of both throughput and the buffer.


196
00:14:51,400 --> 00:14:58,160
For the metrics, we compare the video stops, which is how long the video will be stopped


197
00:14:58,160 --> 00:14:59,160
and to buffer.


198
00:14:59,160 --> 00:15:05,160
And video quality and the video quality variation, which is the smoothness of the video.


199
00:15:05,160 --> 00:15:09,160
Because we know that video can have different quality, between the playback, it can change


200
00:15:09,160 --> 00:15:13,040
quality dramatically or steadily.


201
00:15:13,040 --> 00:15:20,880
And lastly, we compare the quality of experience, which is a standard metric to compare video


202
00:15:20,880 --> 00:15:23,800
streaming under ABR streaming.


203
00:15:23,800 --> 00:15:27,920
So it takes the following three together as one.


204
00:15:27,920 --> 00:15:32,920
And then finally, we evaluate Telescope under various network conditions.


205
00:15:32,920 --> 00:15:35,720
Now let's see some results.


206
00:15:35,720 --> 00:15:39,680
So here is the result from Telescope QoE performance.


207
00:15:39,680 --> 00:15:44,320
As the highlight in yellow, that's Telescope average QoE.


208
00:15:44,320 --> 00:15:50,540
And it compares the QoE against direct video streaming, IPFS, and ABR video streaming.


209
00:15:50,540 --> 00:15:56,040
We can see that Telescope outperformed the traditional ABR by 123%.


210
00:15:56,040 --> 00:15:59,440
And outperformed the direct IPFS streaming by 94%.


211
00:15:59,440 --> 00:16:06,920
However, QoE does not tell the full story, because QoE takes the video stop, video quality,


212
00:16:06,920 --> 00:16:09,320
and video variation together.


213
00:16:09,320 --> 00:16:15,840
So to see how Telescope truly performs, we compare Telescope's average quality against


214
00:16:15,840 --> 00:16:17,720
ABR.


215
00:16:17,720 --> 00:16:22,560
As this figure shows, we evaluate Telescope under different cache settings.


216
00:16:22,560 --> 00:16:27,600
We can see under 60% cache, Telescope outperformed ABR by 48%.


217
00:16:27,600 --> 00:16:31,760
Under 80% cache, Telescope outperformed ABR by 18%.


218
00:16:31,760 --> 00:16:33,780
Now let's see the stalls.


219
00:16:33,780 --> 00:16:37,800
So this figure compared the stall for Telescope and ABR.


220
00:16:37,800 --> 00:16:44,240
As we can see, in both cache settings, Telescope reduced the stall by 91%, which means that


221
00:16:44,240 --> 00:16:51,120
Telescope can stream video with high quality while keep the stall rate low.


222
00:16:51,120 --> 00:16:52,360
So conclusion.


223
00:16:52,360 --> 00:16:57,960
So video stream IPFS performs poorly, currently, due to the high RTT and the single encoding


224
00:16:57,960 --> 00:16:58,960
of the video.


225
00:16:58,960 --> 00:17:04,120
And second is that existing video solution ABR performs poorly with IPFS, because it's


226
00:17:04,120 --> 00:17:06,360
a peer-to-peer nature of it.


227
00:17:06,360 --> 00:17:11,160
And then Telescope improved video streaming with ABR IPFS significantly by incorporating


228
00:17:11,160 --> 00:17:13,240
video source information.


229
00:17:13,240 --> 00:17:17,500
And finally, Telescope introduced a new way to stream video that combined the benefits


230
00:17:17,500 --> 00:17:24,240
of distributed systems and deliver high quality of video streaming.


231
00:17:24,240 --> 00:17:28,240
And for the reference, there's more detail you can find in the paper, which is on my


232
00:17:28,240 --> 00:17:29,240
website.


233
00:17:29,240 --> 00:17:30,240
Thank you.


234
00:17:30,240 --> 00:17:31,240
And any questions?


235
00:17:31,240 --> 00:17:46,040
Telescope is running on the gateway?


236
00:17:46,040 --> 00:17:49,200
It's not run on a gateway.


237
00:17:49,200 --> 00:17:51,360
It's a proxy in between.


238
00:17:51,360 --> 00:17:54,880
But I think, based on today, they have some more advanced gateway.


239
00:17:54,880 --> 00:18:00,120
I think this can be corroborated, embedded into the new advanced gateway, where they


240
00:18:00,120 --> 00:18:04,440
can directly, smartly detect, oh, the user is playing videos.


241
00:18:04,440 --> 00:18:10,280
Now let's make this algorithm in there, so that the user don't have to deploy another


242
00:18:10,280 --> 00:18:11,280
telescope.


243
00:18:11,280 --> 00:18:12,280
Yeah.


244
00:18:12,280 --> 00:18:17,120
So, like, with the microphone.


245
00:18:17,120 --> 00:18:18,120
OK.


246
00:18:18,120 --> 00:18:19,120
It's on?


247
00:18:19,120 --> 00:18:20,120
No, no.


248
00:18:20,120 --> 00:18:21,120
Please, please.


249
00:18:21,120 --> 00:18:22,120
OK.


250
00:18:22,120 --> 00:18:32,280
So, well, streaming a video and assuming you're on a phone and in a car, the connection can


251
00:18:32,280 --> 00:18:34,880
degrade or improve dramatically over time.


252
00:18:34,880 --> 00:18:39,920
Do you do any kind of like smoothing of that throughput estimations during the playback


253
00:18:39,920 --> 00:18:41,080
or fetching the blocks?


254
00:18:41,080 --> 00:18:44,840
Or is it like, once you decide, you stick with it and go all the way?


255
00:18:44,840 --> 00:18:46,920
I'm sorry, can you like...


256
00:18:46,920 --> 00:18:49,680
You mentioned the quality can change throughout the video playback.


257
00:18:49,680 --> 00:18:50,680
Yes, yes.


258
00:18:50,680 --> 00:18:57,320
Do you do like further like adaptation on the fly, in terms of like off your bandwidth


259
00:18:57,320 --> 00:18:58,320
link?


260
00:18:58,320 --> 00:19:01,160
Like, do you update your estimations during the whole duration?


261
00:19:01,160 --> 00:19:05,240
Or do you take the fixed values and then balance between those?


262
00:19:05,240 --> 00:19:08,760
So ABR itself, it will constantly estimate them.


263
00:19:08,760 --> 00:19:14,200
So ABR works by like estimate throughput by like based on the quality and the video it


264
00:19:14,200 --> 00:19:15,200
was choosing.


265
00:19:15,200 --> 00:19:16,200
Right?


266
00:19:16,200 --> 00:19:17,520
So let's say if I'm very good at...


267
00:19:17,520 --> 00:19:18,920
Currently I have a good network condition.


268
00:19:18,920 --> 00:19:20,900
I'm able to retrieve the top quality.


269
00:19:20,900 --> 00:19:24,040
And then my network condition drops.


270
00:19:24,040 --> 00:19:25,280
And then I will fetch...


271
00:19:25,280 --> 00:19:27,320
The ABR client will fetch a lower one.


272
00:19:27,320 --> 00:19:29,560
It will realize it becomes lower.


273
00:19:29,560 --> 00:19:32,760
And then you update estimation over time.


274
00:19:32,760 --> 00:19:34,680
So is that the question you're trying to ask?


275
00:19:34,680 --> 00:19:36,120
For the most part, yes.


276
00:19:36,120 --> 00:19:41,800
I was also aiming at whether there's some sort of smoothing along the estimation.


277
00:19:41,800 --> 00:19:42,800
Yes, there is.


278
00:19:42,800 --> 00:19:44,760
So that it's not just jumping around.


279
00:19:44,760 --> 00:19:47,040
But you actually smooth out the predictions that are out there.


280
00:19:47,040 --> 00:19:49,480
Yeah, so that was the very big reason.


281
00:19:49,480 --> 00:19:50,480
That was...


282
00:19:50,480 --> 00:19:54,080
Let me just try to find the...


283
00:19:54,080 --> 00:19:55,080
So that was the reason, right?


284
00:19:55,080 --> 00:19:58,480
So even though it's suffered, right?


285
00:19:58,480 --> 00:19:59,600
It suffered here.


286
00:19:59,600 --> 00:20:00,600
But it doesn't matter.


287
00:20:00,600 --> 00:20:01,600
It's still there.


288
00:20:30,640 --> 00:20:33,120
on IPFS right now, did you reach out to them?


289
00:20:33,120 --> 00:20:34,520
Because as they run a...


290
00:20:34,520 --> 00:20:34,840
Yes.


291
00:20:34,840 --> 00:20:38,200
...to local cluster, not a local but a private cluster,


292
00:20:38,200 --> 00:20:41,560
they might participate in like testing this.


293
00:20:41,560 --> 00:20:43,440
So we...


294
00:20:43,440 --> 00:20:47,960
So yeah, so why I know we know it's a private cluster


295
00:20:47,960 --> 00:20:49,680
is that we actually contacted them.


296
00:20:49,680 --> 00:20:52,800
It's like, hey, I was wondering why we cannot get the video.


297
00:20:52,800 --> 00:20:54,520
Are you guys using a private cluster?


298
00:20:54,520 --> 00:20:56,800
And then they confirm that you use a private cluster.


299
00:20:56,800 --> 00:20:59,600
And then we didn't think about the collaboration at the time,


300
00:20:59,600 --> 00:21:02,560
but like we can't do that with them because in due to


301
00:21:02,560 --> 00:21:05,520
they don't have APR on them.


302
00:21:05,520 --> 00:21:07,840
And they would be the biggest beneficial.


303
00:21:07,840 --> 00:21:08,240
Yes.


304
00:21:08,240 --> 00:21:08,800
Yes.


305
00:21:08,800 --> 00:21:09,480
Yes.


306
00:21:09,480 --> 00:21:09,960
Good.


307
00:21:19,600 --> 00:21:22,280
You mentioned that there were three metrics that made up


308
00:21:22,280 --> 00:21:25,600
the overall quality of video experience.


309
00:21:25,600 --> 00:21:27,960
And you showed us two of them on their own.


310
00:21:27,960 --> 00:21:32,800
The final one, how much it moves between the quality levels.


311
00:21:32,800 --> 00:21:35,880
Was that very different for the solution?


312
00:21:35,880 --> 00:21:37,720
I didn't show this because I forgot


313
00:21:37,720 --> 00:21:39,760
for like timing and the size issue.


314
00:21:39,760 --> 00:21:42,840
So we observed that KaleScope have little variation


315
00:21:42,840 --> 00:21:45,840
compared to our traditional APR because you won't bounce back


316
00:21:45,840 --> 00:21:49,440
and forth because they know what is cache, what is not cache.


317
00:21:49,440 --> 00:21:52,280
And they will try to stay in that range


318
00:21:52,280 --> 00:21:57,120
so that they don't have to suffer from APRs.


319
00:21:57,120 --> 00:21:59,600
Cool.


320
00:21:59,600 --> 00:22:02,520
I'm just wondering, maybe I missed this in an earlier slide,


321
00:22:02,520 --> 00:22:04,280
but how do we use Telescope today?


322
00:22:04,280 --> 00:22:07,320
Like if I wanted to have my own video streaming node?


323
00:22:07,320 --> 00:22:07,840
Oh, yeah.


324
00:22:07,840 --> 00:22:13,520
So basically in our setup is that you can just deploy.


325
00:22:13,520 --> 00:22:16,680
So instead of asking IPFS gateway,


326
00:22:16,680 --> 00:22:18,400
you will just ask Telescope.


327
00:22:18,400 --> 00:22:21,080
Is that what's the repo URL?


328
00:22:21,080 --> 00:22:24,880
I think it's here.


329
00:22:24,880 --> 00:22:27,600
It's here.


330
00:22:27,600 --> 00:22:28,760
It's slow.


331
00:22:28,760 --> 00:22:31,200
Let's just move.


332
00:22:31,200 --> 00:22:32,080
It's here.


333
00:22:32,080 --> 00:22:33,160
OK.


334
00:22:33,160 --> 00:22:33,840
Cool, thank you.


335
00:22:33,840 --> 00:22:37,480
Yeah, it's more about the software


336
00:22:37,480 --> 00:22:41,960
is to see if it works, proof of concept stage.


337
00:22:41,960 --> 00:22:44,720
We didn't actually fully write it very nicely.


338
00:22:44,720 --> 00:22:45,640
Yeah, it makes sense.


339
00:22:45,640 --> 00:22:46,120
Thanks.


340
00:22:49,480 --> 00:22:52,520
You mentioned in these, the whole blocks


341
00:22:52,520 --> 00:22:54,320
were either cached or uncached.


342
00:22:54,320 --> 00:22:57,240
Does it also adjust on the fly where


343
00:22:57,240 --> 00:22:59,680
some blocks are different quality or cached and uncached?


344
00:22:59,680 --> 00:23:00,960
Yes.


345
00:23:00,960 --> 00:23:03,360
We showed here, we simplified it.


346
00:23:03,360 --> 00:23:06,880
So in actual algorithm, we not only keep the cache on cache,


347
00:23:06,880 --> 00:23:09,680
we also will try to see if different provider is


348
00:23:09,680 --> 00:23:12,680
providing the block, because that couldn't happen.


349
00:23:12,680 --> 00:23:15,040
Let's say this block can be, like during the streaming


350
00:23:15,040 --> 00:23:20,280
session, two peers can be part of providing the whole video.


351
00:23:20,280 --> 00:23:22,880
So we also keep a count down in the paper,


352
00:23:22,880 --> 00:23:28,160
try to make sure that even in this case, the instance changed,


353
00:23:28,160 --> 00:23:30,640
we can still able to update the estimate throughput


354
00:23:30,640 --> 00:23:33,560
to help the client to make a better decision.


355
00:23:33,560 --> 00:23:34,400
Cool, thanks.


356
00:23:38,280 --> 00:23:45,120
So when the performance was very variable,


357
00:23:45,120 --> 00:23:50,080
do you know whether that would be because there


358
00:23:50,080 --> 00:23:53,400
was a new request to go and find the content


359
00:23:53,400 --> 00:23:55,840
from another provider?


360
00:23:55,840 --> 00:23:59,560
So I'm trying to figure out whether the performance


361
00:23:59,560 --> 00:24:02,960
variation comes from the discovery of content


362
00:24:02,960 --> 00:24:05,360
or the transmission of content.


363
00:24:05,360 --> 00:24:08,920
OK, so we also tried the similar experiment


364
00:24:08,920 --> 00:24:14,920
under a very fixed, I guess, local networks, where we pre,


365
00:24:14,920 --> 00:24:16,960
before, we did a simulation where we forced


366
00:24:16,960 --> 00:24:21,120
tell the client and gateway, everyone that you're provided


367
00:24:21,120 --> 00:24:22,760
will be that peer.


368
00:24:22,760 --> 00:24:25,240
So I think the content retrieval part is kind of not


369
00:24:25,240 --> 00:24:28,080
important in the sense that we already forced them, tell them,


370
00:24:28,080 --> 00:24:29,320
OK, you have this peer.


371
00:24:29,320 --> 00:24:32,560
So this has happened even with that.


372
00:24:32,560 --> 00:24:35,680
So I think there's even more, in the sense


373
00:24:35,680 --> 00:24:38,640
that I think there's more problem with the transmission


374
00:24:38,640 --> 00:24:40,520
part rather than the discovery part.


375
00:24:40,520 --> 00:24:41,560
Right, OK.


376
00:24:41,560 --> 00:24:44,160
So that's, I think, I don't know if you


377
00:24:44,160 --> 00:24:46,000
have next steps in this study.


378
00:24:46,000 --> 00:24:49,080
But one of the ones that I would identify


379
00:24:49,080 --> 00:24:54,480
is try to break down in steps what is happening


380
00:24:54,480 --> 00:24:59,160
and then try to identify what to improve, basically.


381
00:24:59,160 --> 00:25:00,400
Is it the discovery part?


382
00:25:00,400 --> 00:25:04,160
So it could be, if it's an over-Kubo,


383
00:25:04,160 --> 00:25:05,560
it could be the DHT part.


384
00:25:05,560 --> 00:25:08,680
Or if it's only the transmission, as you say,


385
00:25:08,680 --> 00:25:13,720
you've got one kind of root CAD which you go and discover.


386
00:25:13,720 --> 00:25:16,960
And then all of the rest come from the same content provider


387
00:25:16,960 --> 00:25:21,600
or the same session, then basically it's a bit swap issue


388
00:25:21,600 --> 00:25:23,560
that we're trying to solve here.


389
00:25:23,560 --> 00:25:25,960
So here is not the bit swap issue.


390
00:25:25,960 --> 00:25:30,840
So the issue is that even though we have the root CAD,


391
00:25:30,840 --> 00:25:32,280
we go straight.


392
00:25:32,280 --> 00:25:34,680
When we try to get that root CAD, the content of root,


393
00:25:34,680 --> 00:25:37,440
like the sub-content of that root CAD,


394
00:25:37,440 --> 00:25:40,560
we can still have different peer to provide it, right?


395
00:25:40,560 --> 00:25:41,080
Yeah.


396
00:25:41,080 --> 00:25:41,580
Yes.


397
00:25:41,580 --> 00:25:45,120
So essentially, here, the main problem


398
00:25:45,120 --> 00:25:48,720
is that with that sub-part of files, I can have,


399
00:25:48,720 --> 00:25:50,680
let's say, it's the first segment.


400
00:25:50,680 --> 00:25:52,800
Some gateway, let's say some gateway,


401
00:25:52,800 --> 00:25:54,440
someone already requested before,


402
00:25:54,440 --> 00:25:56,000
the gateway has the cache.


403
00:25:56,000 --> 00:25:57,760
So they can return very fast.


404
00:25:57,760 --> 00:26:01,280
And now, let's say next segment, it was like the gateway,


405
00:26:01,280 --> 00:26:03,480
no one has requests from the gateway before.


406
00:26:03,480 --> 00:26:05,440
And the gateway has to go find the content


407
00:26:05,440 --> 00:26:09,240
and then serve back to them.


408
00:26:09,240 --> 00:26:11,800
And then that provider have a different throughput


409
00:26:11,800 --> 00:26:13,840
from the client to the gateway, because it's


410
00:26:13,840 --> 00:26:15,760
a different actual different peer.


411
00:26:15,760 --> 00:26:19,200
So that's the differential between that sudden change.


412
00:26:19,200 --> 00:26:22,280
It's happening here, which traditional ABR doesn't


413
00:26:22,280 --> 00:26:22,840
assume that.


414
00:26:22,840 --> 00:26:25,120
Traditional ABR assume that it has a client,


415
00:26:25,120 --> 00:26:26,040
it has the server.


416
00:26:26,040 --> 00:26:26,800
It's fixed.


417
00:26:26,800 --> 00:26:29,560
And then even the change will be at the client side.


418
00:26:29,560 --> 00:26:31,520
It's really happening on the server side.


419
00:26:31,520 --> 00:26:34,000
But in this case, it can be happening on the both.


420
00:26:34,000 --> 00:26:34,680
Yeah.


421
00:26:34,680 --> 00:26:35,160
OK.


422
00:26:35,160 --> 00:26:36,840
So lots of issues to see.


423
00:26:36,840 --> 00:26:41,360
And do you have any next steps that you'd like to do with that?


424
00:26:41,360 --> 00:26:43,560
I think the next step, as we discussed,


425
00:26:43,560 --> 00:26:47,920
next step is how the cache, how can we


426
00:26:47,920 --> 00:26:50,480
help using caching to help the stream.


427
00:26:50,480 --> 00:26:51,000
Yeah.


428
00:26:51,000 --> 00:26:52,000
Yeah.


429
00:26:52,000 --> 00:26:52,880
Excellent.


430
00:26:52,880 --> 00:26:53,400
OK.


431
00:26:53,400 --> 00:26:54,280
Thank you very much.


432
00:26:54,280 --> 00:26:54,780
Any other?


433
00:27:01,040 --> 00:27:02,560
Hey there.


434
00:27:02,560 --> 00:27:07,760
So I guess just to be clear, with the comparison


435
00:27:07,760 --> 00:27:10,880
with Telescope and the traditional way,


436
00:27:10,880 --> 00:27:14,640
or the other way was through the IPFS gateway,


437
00:27:14,640 --> 00:27:17,480
not directly to the IPFS network?


438
00:27:17,480 --> 00:27:18,200
Yes.


439
00:27:18,200 --> 00:27:19,400
OK.


440
00:27:19,400 --> 00:27:20,480
Yes.


441
00:27:20,480 --> 00:27:21,520
Yeah.


442
00:27:21,520 --> 00:27:22,200
OK.


443
00:27:22,200 --> 00:27:24,400
Have you considered connecting to the peers


444
00:27:24,400 --> 00:27:25,760
directly on the IPFS network?


445
00:27:25,760 --> 00:27:26,260
OK.


446
00:27:26,260 --> 00:27:28,400
So we thought about the idea, but I


447
00:27:28,400 --> 00:27:33,320
think as a usability side of it, it was IPFS gateway


448
00:27:33,320 --> 00:27:34,760
is more natural for the user.


449
00:27:34,760 --> 00:27:36,760
Like, they just type the URL, they


450
00:27:36,760 --> 00:27:39,320
start to stream the video.


451
00:27:39,320 --> 00:27:42,000
And we said this way because it's more convenient,


452
00:27:42,000 --> 00:27:45,080
like more practical than having a user


453
00:27:45,080 --> 00:27:47,520
to connect the peer directly.


454
00:27:47,520 --> 00:27:50,680
That's what our kind of motivation is.


455
00:27:50,680 --> 00:27:53,040
And also Telescope can, the reason


456
00:27:53,040 --> 00:27:56,120
we opted the manifest file, because that way we


457
00:27:56,120 --> 00:27:57,680
don't have to modify the client.


458
00:27:57,680 --> 00:28:00,600
A peer client works as everyone can plug in and pay.


459
00:28:00,600 --> 00:28:02,280
They don't have to modify their code.


460
00:28:02,280 --> 00:28:05,520
Any peer can work as it is.


461
00:28:05,520 --> 00:28:07,060
And that's another key part of that way


462
00:28:07,060 --> 00:28:08,400
we designed the system like this.


463
00:28:10,960 --> 00:28:11,560
Cool.


464
00:28:11,560 --> 00:28:28,600
Thank you.
