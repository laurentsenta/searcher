1
00:00:00,000 --> 00:00:11,200
Welcome to my talk on hole punching in the wild. It's a small disclaimer here. We gave


2
00:00:11,200 --> 00:00:18,040
this talk previously at FOSDEM in 2023, so this year actually. But I thought maybe this


3
00:00:18,040 --> 00:00:23,120
is actually useful for this audience as well to hear this talk or this talk in a similar


4
00:00:23,120 --> 00:00:29,640
way as like a lot of work went into general like hole punching measurements and hole punching


5
00:00:29,640 --> 00:00:35,000
in general in libp2p. And so this is kind of carrying this information to this audience


6
00:00:35,000 --> 00:00:42,920
as well. Cool. So what I want to talk about is libp2p, libp2p's hole punching mechanism.


7
00:00:42,920 --> 00:00:48,560
We'll go into what hole punching actually is and then hole punching deployed onto the


8
00:00:48,560 --> 00:00:54,440
IPFS network or other networks. And then last step being measuring the success rate of this


9
00:00:54,440 --> 00:01:03,320
hole punching mechanism off libp2p. Okay. Yeah. We did this together or actually there's


10
00:01:03,320 --> 00:01:10,680
a third person as well, which is Elena, building the whole project around measuring hole punching.


11
00:01:10,680 --> 00:01:16,960
And then Dennis collected a lot of data, executed the whole measurement campaign and so on.


12
00:01:16,960 --> 00:01:21,400
Janice also helped a lot on the measurement campaign and collected all the data. I'm still


13
00:01:21,400 --> 00:01:25,680
listing Dennis here as we prepared the talk together, but unfortunately Dennis can't make


14
00:01:25,680 --> 00:01:32,160
it today. Short introduction for myself, Max, software engineer at Protocol Labs, maintaining


15
00:01:32,160 --> 00:01:40,640
libp2p among many others, of course. Okay. Let's look quickly on the agenda. I would


16
00:01:40,640 --> 00:01:44,640
like to give a very brief intro to libp2p, even though I would guess most people are


17
00:01:44,640 --> 00:01:48,400
already familiar here. Then talk a little bit about the problems that we're actually


18
00:01:48,400 --> 00:01:53,400
facing in libp2p, which is firewalls and NATs. We're facing many other problems as well,


19
00:01:53,400 --> 00:01:59,760
but we will not focus on those here today. The holy solution or the biggest hack of the


20
00:01:59,760 --> 00:02:04,000
internet called hole punching and then how we measured this and what are kind of the


21
00:02:04,000 --> 00:02:11,760
takeaways from this larger measurement campaign. Okay. Cool. Again, short show of hands, who


22
00:02:11,760 --> 00:02:22,000
here has ever used libp2p? Okay. Cool. Anyone that used IPFS obviously also used libp2p.


23
00:02:22,000 --> 00:02:26,420
So libp2p, peer-to-peer networking library, one specification then implemented in many


24
00:02:26,420 --> 00:02:32,800
different languages. It provides low level features like encryption, authentication,


25
00:02:32,800 --> 00:02:37,240
and hole punching, which we're going to talk about today, and then higher level features


26
00:02:37,240 --> 00:02:41,820
like for example, DHT, a distributed hash table, or gossiping protocols that then build


27
00:02:41,820 --> 00:02:46,400
on those lower layers that we built. Okay. And then in general, I would say libp2p is


28
00:02:46,400 --> 00:02:54,360
all you need or should be all you need to build a peer-to-peer application. Okay. So


29
00:02:54,360 --> 00:02:59,960
we're going to focus on hole punching. And why do we need hole punching in the first


30
00:02:59,960 --> 00:03:06,000
place? Well, we want within the libp2p network, we want full connectivity among all nodes,


31
00:03:06,000 --> 00:03:11,440
or at least we want to strive towards full connectivity. And in today's internet, the


32
00:03:11,440 --> 00:03:16,380
biggest barrier to full connectivity is on the one side browsers, which we'll not talk


33
00:03:16,380 --> 00:03:22,960
about today, and then on the other side, NATs and firewalls. Yeah. So we somehow have to


34
00:03:22,960 --> 00:03:27,640
overcome NATs and firewalls to then actually achieve full connectivity within a libp2p


35
00:03:27,640 --> 00:03:33,200
network. Cool. Yeah. Not going to dive deep into what are NATs and firewalls. NATs, network


36
00:03:33,200 --> 00:03:40,480
address insulators, they go from a simplified, from a local public IP to a public IP. Right?


37
00:03:40,480 --> 00:03:45,400
They do this mapping. And then firewalls, small disclaimer, I'm not advocating for all


38
00:03:45,400 --> 00:03:50,600
of you to turn off your firewalls. Please don't do that. But the firewalls have a very


39
00:03:50,600 --> 00:03:54,680
important role. They protect you from outside traffic. Right? And in most cases, you actually


40
00:03:54,680 --> 00:03:59,920
don't want anyone to be able to connect to you. You actually don't want that full connectivity.


41
00:03:59,920 --> 00:04:05,260
But in our case, we do want that. And then the one thing that we're going to work with


42
00:04:05,260 --> 00:04:13,040
today during the talk is the NAT table. It's just a representation. Right? Every model


43
00:04:13,040 --> 00:04:19,120
is wrong, but this is actually useful. You have a table of five tuples, source IP, source


44
00:04:19,120 --> 00:04:24,440
port, destination IP, destination port, and then the transport protocol. And every router,


45
00:04:24,440 --> 00:04:28,460
or in most cases, the NATs and firewalls are actually in the router. Every router keeps


46
00:04:28,460 --> 00:04:35,440
track of this table. And we need this later on to do the hole punching. Cool. So what


47
00:04:35,440 --> 00:04:40,480
is the problem? By the way, in case you find these graphs fancy, none of them were created


48
00:04:40,480 --> 00:04:46,240
by me. All of them were created by Dennis. So let's say A wants to connect to B. So A


49
00:04:46,240 --> 00:04:54,160
sends a packet to B. That will add an entry on the very left to its routing table. Right?


50
00:04:54,160 --> 00:04:59,920
To its NAT mapping table. And then the packet will make it through the Internet somehow.


51
00:04:59,920 --> 00:05:05,120
Right? It's routed through the Internet. And then makes it to router B. And router B will


52
00:05:05,120 --> 00:05:11,800
check its table and discard it. Because it has never seen any packet going from B to


53
00:05:11,800 --> 00:05:17,400
A. So it will think that this packet is coming from an attacker. Right? Or from some malicious


54
00:05:17,400 --> 00:05:23,360
source out there. So better to drop it. And that's a good feature of a firewall. Right?


55
00:05:23,360 --> 00:05:28,600
So how can we overcome this in situations where we actually want those to be able to


56
00:05:28,600 --> 00:05:33,920
connect to each other? So let's say we have some mechanism. We'll go into what that mechanism


57
00:05:33,920 --> 00:05:39,640
is. But let's say we have some mechanism that will have A and B start a process at the same


58
00:05:39,640 --> 00:05:45,880
time. Right? So let's say... Let's go. A and B both send a packet at the same time. That


59
00:05:45,880 --> 00:05:52,320
packet traverses their routers. That adds entries to their tables. And those packets


60
00:05:52,320 --> 00:05:58,440
somehow meet in the middle, go the other way, end up at the other person's router. And ta-da!


61
00:05:58,440 --> 00:06:03,280
You have entries in each of these tables. And the routers will let the packets go through.


62
00:06:03,280 --> 00:06:09,960
Right? And this process is called hole punching. Where A punches a hole into its own router


63
00:06:09,960 --> 00:06:17,600
so that the packet from B can make it through that hole into node A. Okay. Again, very much


64
00:06:17,600 --> 00:06:24,760
simplified. There's a lot more details to this. But I think this is helpful here. Okay.


65
00:06:24,760 --> 00:06:31,640
So now I talked about this magic process. Right? How can we achieve that A and B start


66
00:06:31,640 --> 00:06:35,760
this process at the same time? How do we achieve that they both send the packet at the same


67
00:06:35,760 --> 00:06:44,520
time? In lib2p world, this is called DCUTR. Decutter by some direct connection upgrade


68
00:06:44,520 --> 00:06:52,040
through relay. Don't remember the name. That's fine. In other protocols, like for example


69
00:06:52,040 --> 00:06:57,800
WebRTC, you do this coordination over turn, for example. So how do we synchronize somehow?


70
00:06:57,800 --> 00:07:04,920
Well, in lib2p, we first introduce a relay. So we have both A and B connect to the relay


71
00:07:04,920 --> 00:07:10,720
node. And then we at least have a relayed way to communicate with each other. And what


72
00:07:10,720 --> 00:07:16,680
we want to achieve now is a direct connection between the two nodes. So once we have the


73
00:07:16,680 --> 00:07:24,000
relayed connection, B will send a connect message to A. And it will actually start a


74
00:07:24,000 --> 00:07:31,840
timer. It will start measuring the round trip time. The connect will go through the relayed


75
00:07:31,840 --> 00:07:37,640
connection. Again, we don't have a direct connection yet. It will arrive at A. And A


76
00:07:37,640 --> 00:07:43,560
will send a connect back. So at this point, you can see that B knows


77
00:07:43,560 --> 00:07:50,080
roughly the round trip time between B and A over the relay. What it will do now, it


78
00:07:50,080 --> 00:07:55,160
will send a sync message. And it will wait half a round trip time. So half a round trip


79
00:07:55,160 --> 00:08:00,280
time is exactly the time the sync message will need it to A. And after half a round


80
00:08:00,280 --> 00:08:06,440
trip time, B will start the hole punching. And when A receives the sync, it will start


81
00:08:06,440 --> 00:08:11,640
the hole punching. So ta-da, we have our magical mechanism that actually synchronizes the two


82
00:08:11,640 --> 00:08:17,400
and have them do a hole punching at the same time.


83
00:08:17,400 --> 00:08:23,260
So then the packets are sent out at the same time. They traverse somewhere in the internet.


84
00:08:23,260 --> 00:08:27,360
They make it to the other side. And ta-da, they make it through the routers. And this


85
00:08:27,360 --> 00:08:35,280
way, we actually achieved a hole punch. Okay. Cool. So that's how we do hole punching


86
00:08:35,280 --> 00:08:41,760
in Lip2P. And hole punching is not specific to Lip2P. We're definitely not the inventors


87
00:08:41,760 --> 00:08:47,480
of, in my eyes, the biggest hack of the internet. This has probably been done before 2008, I'm


88
00:08:47,480 --> 00:08:54,400
very sure. But the most official reference I've found is in RFC 5128. It's actually quite


89
00:08:54,400 --> 00:09:01,480
amusing to see this fully documented. Implementations in Lip2P started before 2021.


90
00:09:01,480 --> 00:09:06,880
But since 2021, between 2021 and 2022, we have been specifying most of the protocols


91
00:09:06,880 --> 00:09:13,840
and then implementing both protocols in Go and Rust. At Fosdem last year, we actually


92
00:09:13,840 --> 00:09:18,760
announced or not announced, but we talked about most of this and then started rolling


93
00:09:18,760 --> 00:09:27,400
this out on the IPFS network in roughly summer 2022. And, well, rolling this out is one step,


94
00:09:27,400 --> 00:09:34,000
but the next step is how can we actually make sure this works properly, right? And for that,


95
00:09:34,000 --> 00:09:41,280
Dennis organized the so-called hole punching month, where we tried to measure how well


96
00:09:41,280 --> 00:09:47,920
is hole punching actually working across the many networks that are using IPFS.


97
00:09:47,920 --> 00:09:56,840
All right. So how do you measure hole punching? Well, what we could do is just have one colleague


98
00:09:56,840 --> 00:10:02,000
run their laptop, have me run my laptop, right? And then we do hole punching. But now there


99
00:10:02,000 --> 00:10:06,760
is so much complexity in here. Like how does my laptop's network stack look like, right?


100
00:10:06,760 --> 00:10:10,920
How does my internal network look like? What is my router? What's the NAT behavior of my


101
00:10:10,920 --> 00:10:16,000
router? What's the firewall of my router? What is my ISP? How fast does my ISP route


102
00:10:16,000 --> 00:10:20,280
to the other ISP? And then everything mirrored on the other side as well, right? So there's


103
00:10:20,280 --> 00:10:25,240
so much complexity that if we simply test it between two endpoints, we'll get one data


104
00:10:25,240 --> 00:10:29,920
point. But that data point is pretty much useless as the internet is so diverse out


105
00:10:29,920 --> 00:10:31,800
there.


106
00:10:31,800 --> 00:10:36,680
So we set out for something different. We had many ideas. This is the simplest solution,


107
00:10:36,680 --> 00:10:44,440
I would say. What we first do is we have a honeypot. So you can think of this as in the


108
00:10:44,440 --> 00:10:50,800
concept in the security world. So we have a DHT server in the IPFS network that simply


109
00:10:50,800 --> 00:10:57,520
tries to attract other nodes. And among those nodes are nodes behind firewalls and NATs,


110
00:10:57,520 --> 00:11:03,520
right? Just standard IPFS users out there. Now these users announce themselves to the


111
00:11:03,520 --> 00:11:08,080
network and somehow come across our honeypot, right? Given the cadamular DHT, they will


112
00:11:08,080 --> 00:11:15,560
at some point connect to it. And the honeypot will forward those connection information


113
00:11:15,560 --> 00:11:21,040
of those nodes behind NATs and firewalls to a database. And then on the other side of


114
00:11:21,040 --> 00:11:27,200
the database, we have a server which kind of exposes this data to our clients.


115
00:11:27,200 --> 00:11:33,620
Now the clients are special hole-punching month clients. We built this in Go and Rust.


116
00:11:33,620 --> 00:11:38,320
And we asked many people to deploy a small little binary, a small client, in their network


117
00:11:38,320 --> 00:11:43,160
and just have it running for long term. And what the clients do, those are not IPFS clients.


118
00:11:43,160 --> 00:11:49,200
So those are very spec down clients. What the clients do, they connect to the server,


119
00:11:49,200 --> 00:11:56,120
get addresses of a bunch of other IPFS nodes out there that are behind firewalls and NATs.


120
00:11:56,120 --> 00:12:01,160
They will try to connect to the relay node of those IPFS clients behind firewalls and


121
00:12:01,160 --> 00:12:07,160
NATs. And then they will actually try to do a hole-punch between those. And what they


122
00:12:07,160 --> 00:12:14,200
are then going to do is report the result back to the server. And this way, we pretty


123
00:12:14,200 --> 00:12:19,960
much tested hole-punching across the entire globe.


124
00:12:19,960 --> 00:12:25,200
So this graph shows in which countries we actually had those hole-punching clients.


125
00:12:25,200 --> 00:12:33,520
So not real IPFS clients, but spec down clients of people running in their home networks.


126
00:12:33,520 --> 00:12:41,440
And these are the remote clients, so the standard IPFS clients running behind NATs and firewalls.


127
00:12:41,440 --> 00:12:46,440
And so we basically punch holes in the direction from the puncher clients down to the remote


128
00:12:46,440 --> 00:12:47,440
peers.


129
00:12:47,440 --> 00:12:54,800
Yeah, a couple more things. So it roughly went for a month. We have above 6 million


130
00:12:54,800 --> 00:13:02,200
hole-punches. We have roughly 150 clients. So those clients that run into people's network


131
00:13:02,200 --> 00:13:06,200
where we asked, hey, can you please deploy this client in your network for a longer period


132
00:13:06,200 --> 00:13:15,000
of time? And then we're roughly talking about 50k peers that we punched, too.


133
00:13:15,000 --> 00:13:23,200
All right, so overall success rate, to summarize in one number, is roughly 70%. So 70% success


134
00:13:23,200 --> 00:13:28,920
rate to establish a direct connection between two peers behind firewalls and NATs on the


135
00:13:28,920 --> 00:13:35,800
IPFS network. But there is a lot more to this, and I want to draw attention to a couple of


136
00:13:35,800 --> 00:13:38,000
the details.


137
00:13:38,000 --> 00:13:44,680
So probably the most interesting one is success rate. So what you see here on the left is


138
00:13:44,680 --> 00:13:52,280
the number of networks, and then towards the right, the success rate. And what you can


139
00:13:52,280 --> 00:13:56,680
see is, well, we have some networks on the very left where it's simply a success rate


140
00:13:56,680 --> 00:14:02,000
to zero. This could, for example, be symmetric NATs. I can go into detail what that is. We


141
00:14:02,000 --> 00:14:07,800
simply can't hole-punch those at the moment. But what you can also see is that we have


142
00:14:07,800 --> 00:14:13,480
a big chunk of networks where actually success rate is very high. You see the big spike.


143
00:14:13,480 --> 00:14:16,840
So that's very promising to continue doing hole-punching.


144
00:14:16,840 --> 00:14:24,880
Then how does this relate to TCP and QUIC? There is a lot more detail to this, but surprisingly


145
00:14:24,880 --> 00:14:29,840
we haven't seen a big distinction between the two. We would have expected QUIC, given


146
00:14:29,840 --> 00:14:35,600
as UDP, and given that thus the NAT behavior is very different, to outperform TCP by a


147
00:14:35,600 --> 00:14:41,960
big chunk, but we haven't seen that. And then we seem to have some problems on IPv6, but


148
00:14:41,960 --> 00:14:48,160
we haven't really dug deep into why we have such a low success rate on IPv6 across TCP


149
00:14:48,160 --> 00:14:49,880
and QUIC.


150
00:14:49,880 --> 00:14:58,040
All right. So this is a very, very misleading chart, I would say. So you would think that,


151
00:14:58,040 --> 00:15:06,840
well, 80% of the successes, hole-punch successes, were QUIC and 18.9% were TCP. That is correct.


152
00:15:06,840 --> 00:15:13,960
But if two peers try to connect to each other, we will erase different transports. So we'll


153
00:15:13,960 --> 00:15:20,840
connect over TCP and QUIC at the same time. And, well, maybe the TCP connection succeeded,


154
00:15:20,840 --> 00:15:26,280
but we actually don't know, because QUIC is so much faster at the handshake, it only needs


155
00:15:26,280 --> 00:15:32,520
one round trip for the handshake, that we simply... QUIC is just the fastest, and at


156
00:15:32,520 --> 00:15:37,560
some point, once we have one connection established, we just don't bother about the TCP connection


157
00:15:37,560 --> 00:15:44,600
anymore. So yes, QUIC is widely outperforming here at TCP, but this is due to the fact that


158
00:15:44,600 --> 00:15:49,440
QUIC is simply faster at reporting a successful result of a hole-punch. Maybe the TCP connections


159
00:15:49,440 --> 00:15:53,080
would have succeeded, but we don't know at this point.


160
00:15:53,080 --> 00:16:01,520
Cool. Another complexity is the virtual private networks. The problem here is that, in general,


161
00:16:01,520 --> 00:16:05,600
you would think that you're, as your laptop, you're very close to your router, to your


162
00:16:05,600 --> 00:16:10,520
home router, right? You would think of, like, at most one millisecond or something. But


163
00:16:10,520 --> 00:16:16,840
in the case of virtual VPNs, your exit point is very far away. So that screws with a lot


164
00:16:16,840 --> 00:16:21,080
of the measurements that we do. You remember earlier this magic mechanism that I said,


165
00:16:21,080 --> 00:16:27,400
where, like, yeah, we try to time the two endpoints to hole-punch at the same time,


166
00:16:27,400 --> 00:16:32,440
right? This is very difficult on VPNs, because the part that you want to hole-punch is not


167
00:16:32,440 --> 00:16:38,000
right next to you, but a lot further away. And in case that's very much further away,


168
00:16:38,000 --> 00:16:42,880
the hole-punch will not succeed. So that's why we have significantly less success rate


169
00:16:42,880 --> 00:16:49,800
on virtual private networks. Another takeaway is what we do in hole-punching


170
00:16:49,800 --> 00:16:55,240
is we don't try once, but we try multiple times. So in total, we try three times to


171
00:16:55,240 --> 00:16:59,840
hole-punch to a remote peer. And what the measurements pretty much show is, in case


172
00:16:59,840 --> 00:17:04,760
it didn't succeed on the first try, like, there's no reason to try again. But I'll add


173
00:17:04,760 --> 00:17:11,560
a little caveat in a little bit. So that's definitely a learning, and we can skip the


174
00:17:11,560 --> 00:17:15,360
other two. And then lastly, what I would have expected


175
00:17:15,360 --> 00:17:20,720
is that the round-trip time to the relay really matters. So, for example, if two nodes within


176
00:17:20,720 --> 00:17:25,280
Europe want to hole-punch, I would have expected that the round-trip time in case the relay


177
00:17:25,280 --> 00:17:30,000
is in the US, that this really matters. But we haven't really found a correlation between


178
00:17:30,000 --> 00:17:35,280
the round-trip time to the relay and the round-trip time. Whether the round-trip time to the relay


179
00:17:35,280 --> 00:17:39,880
really matters in terms of success rate on a hole-punching. That was quite a surprise.


180
00:17:39,880 --> 00:17:44,880
I would have expected, given that the two European nodes are right next to each other,


181
00:17:44,880 --> 00:17:51,440
that this is quite a problem with the US relay, because any timing problems that can happen


182
00:17:51,440 --> 00:17:57,320
on such a long path really screw up our timing between the two European nodes.


183
00:17:57,320 --> 00:18:04,960
All right. So next steps, a couple of learnings. Well, we need to reconsider the retries. Then


184
00:18:04,960 --> 00:18:10,400
on QUIC, we can actually still do the retries. What we're currently doing is one tries to


185
00:18:10,400 --> 00:18:14,880
establish a connection, and the other one just sends garbage. In case one of the two


186
00:18:14,880 --> 00:18:19,720
is a symmetric NAT, we should try doing it the other way around. So one sending the garbage,


187
00:18:19,720 --> 00:18:23,320
and one trying to establish the connection. So we'll probably have higher success rate


188
00:18:23,320 --> 00:18:24,320
there.


189
00:18:24,320 --> 00:18:30,080
And then we can probably do some optimizations around RTT measurements, better RTT measurements,


190
00:18:30,080 --> 00:18:34,560
not to the remote peer, but actually as well to our gateway. So this way, we could, for


191
00:18:34,560 --> 00:18:40,800
example, discover that we are in a VPN, where our exit node, well, the VPN exit node, is


192
00:18:40,800 --> 00:18:44,640
very far away. So the thing that we need to hole-punch is further away than the standard


193
00:18:44,640 --> 00:18:45,640
router.


194
00:18:45,640 --> 00:18:53,000
All right. The entire data analysis, again, done by Dennis. I would assume that this is


195
00:18:53,000 --> 00:18:58,240
available in case people are interested in the data. I don't think it's available publicly,


196
00:18:58,240 --> 00:19:04,360
but I would guess reach out in case you're interested in this large chunk of data. And


197
00:19:04,360 --> 00:19:09,760
yeah, we still have to root cause a lot of things on this.


198
00:19:09,760 --> 00:19:15,360
Cool. We published a paper on decentralized hole-punching. So how does hole-punching work


199
00:19:15,360 --> 00:19:24,320
in LipidP? Main author here is Martin. And then since then, Dennis wrote up a very extensive


200
00:19:24,320 --> 00:19:30,040
report on all of the measurement data. So if you want to check out that part, I think,


201
00:19:30,040 --> 00:19:34,040
over the GitHub repository is the best way to find it, right?


202
00:19:34,040 --> 00:19:38,080
And yeah, so just go to protocol slash network measurements, and you find a bunch of really


203
00:19:38,080 --> 00:19:43,600
good, in my eyes, requests for measurement reports there. And one of them is the hole-punching


204
00:19:43,600 --> 00:19:48,360
measurement report going into every detail of the data.


205
00:19:48,360 --> 00:19:57,920
All right. That's all from my side. Thank you.


206
00:19:57,920 --> 00:20:16,240
Any questions on hole-punching?


207
00:20:01,000 --> 00:20:12,000
So Max, so is the is the timing on UDP packet response traversal so fine-grained that the sync packet is necessary?


208
00:20:12,000 --> 00:20:18,000
You know what I mean? Like you said, you had to send the sync because you're trying to get the endpoints to time their hole-punch.


209
00:20:18,000 --> 00:20:30,000
What is the typical timeout on a NAT firewall where it will allow an inbound packet, you know, as a response rather than reject it?


210
00:20:30,000 --> 00:20:33,000
Like what is that timing? Is the sync packet actually necessary?


211
00:20:33,000 --> 00:20:42,000
Yeah. So the sync mechanism we mostly build to hole-punch for TCP. If we have the sync anyways, might as well use it for UDP as well.


212
00:20:42,000 --> 00:20:52,000
But probably the WebRTC way would be the better one. If we just would be doing UDP where we just, yeah, just shoot a bunch of UDP packets out.


213
00:20:52,000 --> 00:20:55,000
And this way punch holes into our own NATs.


214
00:20:55,000 --> 00:21:07,000
Right. Because in your measurements, did you, I don't know how you would track it, but did you track the sync packet failing to get to the other side?


215
00:21:07,000 --> 00:21:13,000
And therefore the other side didn't try to hole-punch back? And that is like a source of false negatives?


216
00:21:13,000 --> 00:21:19,000
So the sync packet would never fail in that sense, given that we have retransmits on our transport layer.


217
00:21:19,000 --> 00:21:26,000
But that makes it even worse, right? Because retransmits screw up your entire measurement. We have not gone into that, no.


218
00:21:26,000 --> 00:21:30,000
Sure. And you said you haven't done any root causing on the IPv6 stuff?


219
00:21:30,000 --> 00:21:39,000
No, we haven't. Yeah, I would guess it's a silly mistake on our end. It might even just be in our puncher clients. We haven't. I just wanted to disclose it here.


220
00:21:39,000 --> 00:21:41,000
Great talk though, by the way.


221
00:21:41,000 --> 00:21:48,000
Thanks. Anyone else? Any nitty gritty details about NATs?


222
00:21:48,000 --> 00:21:56,000
One question regarding the relays. You said you would have expected that relays in the US make a difference.


223
00:21:56,000 --> 00:22:04,000
But really the packet only needs to make it out of my router and to the relay before the other one comes back.


224
00:22:04,000 --> 00:22:13,000
So I guess if the relay is very far apart, that time to the router is so much shorter than to the relay,


225
00:22:13,000 --> 00:22:22,000
that probably by the time you're telling the other party to start, your packet already made it out of the router, even if it already made it to the other side.


226
00:22:22,000 --> 00:22:27,000
It might have already made it out of your router, but it might have also already made it into the other person's router,


227
00:22:27,000 --> 00:22:32,000
even though they don't yet know whether we're doing hole punching or not. Does that make sense?


228
00:22:32,000 --> 00:22:33,000
Right. Yeah.


229
00:22:33,000 --> 00:22:43,000
So it's like, yes, like, can I show this somewhere? So we do the relay, right? We do the connect, then we do the sync, right?


230
00:22:43,000 --> 00:22:57,000
We have the sync, and let's say the relay is so far away that actually this sync, the packet from B actually overtakes the sync and makes it to A's router first.


231
00:22:57,000 --> 00:23:02,000
And then A's router is like, I don't have an entry for this. I'll drop the packet.


232
00:23:02,000 --> 00:23:07,000
So, yeah, I would still expect this to be problematic, but we haven't found it in the data.


233
00:23:07,000 --> 00:23:16,000
It doesn't mean, what do you say, like, missing proof of existence doesn't mean it doesn't exist.


234
00:23:16,000 --> 00:23:17,000
You had another question?


235
00:23:17,000 --> 00:23:25,000
Yeah, it was in the same direction. I was thinking that it would be beneficial for the VPNs to purposely choose a relay in the US.


236
00:23:25,000 --> 00:23:26,000
Mm-hmm.


237
00:23:26,000 --> 00:23:30,000
Ah. Why?


238
00:23:30,000 --> 00:23:31,000
To be far away enough.


239
00:23:31,000 --> 00:23:37,000
Yeah, to increase the delay after your exit point.


240
00:23:37,000 --> 00:23:39,000
Okay, yeah.


241
00:23:39,000 --> 00:23:44,000
So you're saying if your VPN exits in Europe, take a relay in the US to slow it down?


242
00:23:44,000 --> 00:23:52,000
So just to repeat, like, the idea is to pick up a far relay in case you're behind a VPN.


243
00:23:52,000 --> 00:24:03,000
So you make the first attempt, you see it fails. Usually you would say, okay, another attempt wouldn't help, but then purposely pick a relay with higher latency further away to make up for it.


244
00:24:03,000 --> 00:24:06,000
Yeah. Or wait a little bit after your sync.


245
00:24:06,000 --> 00:24:09,000
Yeah, probably easier.


246
00:24:09,000 --> 00:24:21,000
I don't know. At this point, I think we should do, like, try mostly, like, really buckle down on UDP and just send a constant stream of UDP packets both directions and hope that one of them makes it.


247
00:24:21,000 --> 00:24:23,000
Yeah.


248
00:24:23,000 --> 00:24:24,000
Thanks.


249
00:24:24,000 --> 00:24:32,000
Cool.


250
00:24:32,000 --> 00:24:34,000
I have a quick question.


251
00:24:34,000 --> 00:24:52,000
So after this great study that we did and all of the stuff that you've built together with Dennis and everyone, like, what is the, how did the results change what you would do with not hole punching in libb to be?


252
00:24:52,000 --> 00:24:55,000
What are, did you change course of action?


253
00:24:55,000 --> 00:25:01,000
Do you have any extra items that you now want to fix for the next release?


254
00:25:01,000 --> 00:25:03,000
Like, yeah.


255
00:25:03,000 --> 00:25:04,000
Okay.


256
00:25:04,000 --> 00:25:06,000
So one thing that was super helpful.


257
00:25:06,000 --> 00:25:10,000
So in general, go lipid B was very much ahead on hole punching.


258
00:25:10,000 --> 00:25:18,000
And what we could actually do on the rest side is, well, we basically had free hole punching partners through this architecture, right?


259
00:25:18,000 --> 00:25:25,000
Because we could test against all of the IPFS nodes that are behind firewalls and that's due to this honeypot architecture.


260
00:25:25,000 --> 00:25:36,000
And this led to finding many things on the rest lipid B side where we could actually do optimizations like we were not choosing our alternate servers correctly.


261
00:25:36,000 --> 00:25:38,000
We were not.


262
00:25:38,000 --> 00:25:40,000
Yeah, I have to look them up, but we did a bunch of things.


263
00:25:40,000 --> 00:25:42,000
So that was definitely very fruitful.


264
00:25:42,000 --> 00:25:55,000
Then I would guess that there's retry mechanism here on UDP hole punching will be fruitful, but we haven't actually investigated this one.


265
00:25:55,000 --> 00:26:05,000
And then I think just discovering the fact that we have difficulties on IPV six will be fruitful, but again, we haven't, do we, do we know yet?


266
00:26:05,000 --> 00:26:06,000
I don't know.


267
00:26:06,000 --> 00:26:08,000
I also don't want to give it too much attention.


268
00:26:08,000 --> 00:26:11,000
Maybe it's just a silly bug in our implementation.


269
00:26:11,000 --> 00:26:12,000
Yeah.


270
00:26:12,000 --> 00:26:13,000
Cool.


271
00:26:13,000 --> 00:26:14,000
Okay.


272
00:26:14,000 --> 00:26:15,000
Excellent.


273
00:26:15,000 --> 00:26:16,000
Yeah.


274
00:26:16,000 --> 00:26:28,000
So, um, what protocols are keeping lib P2P firmly in the supporting TCP?


275
00:26:28,000 --> 00:26:32,000
Ah, some ISPs drop UDP just by default.


276
00:26:32,000 --> 00:26:33,000
Yeah.


277
00:26:33,000 --> 00:26:35,000
There's nothing good coming in through UDP.


278
00:26:35,000 --> 00:26:39,000
That's interesting.


279
00:26:39,000 --> 00:26:41,000
In the past, right?


280
00:26:41,000 --> 00:26:42,000
Obviously.


281
00:26:42,000 --> 00:26:43,000
Yeah, I get that.


282
00:26:43,000 --> 00:26:47,000
I'm just saying, but right now, like, is it really just TLS HTTP?


283
00:26:47,000 --> 00:26:49,000
Like, I mean, are these.


284
00:26:49,000 --> 00:26:55,000
So like literally still ISPs drop UDP packets, so we can't run quick in those networks.


285
00:26:55,000 --> 00:26:58,000
How big is that?


286
00:26:58,000 --> 00:27:00,000
So anyway, sorry, I don't want to derail this.


287
00:27:00,000 --> 00:27:04,000
I think it's somewhere within the 5% ballpark, but this could be completely off.


288
00:27:04,000 --> 00:27:09,000
Like, it's definitely something that is still relevant, for example, at the ITF and still considered.


289
00:27:09,000 --> 00:27:12,000
No, I'm not saying it's not relevant.


290
00:27:12,000 --> 00:27:16,000
Just wondering how hard we can push the web three part of this.


291
00:27:16,000 --> 00:27:17,000
Yeah.


292
00:27:17,000 --> 00:27:18,000
Okay.


293
00:27:18,000 --> 00:27:19,000
Anyway, cool.


294
00:27:19,000 --> 00:27:20,000
Thank you.


295
00:27:20,000 --> 00:27:40,000
Thanks for having me.
