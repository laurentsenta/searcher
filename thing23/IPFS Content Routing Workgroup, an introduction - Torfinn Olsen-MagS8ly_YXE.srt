1
00:00:00,000 --> 00:00:11,920
Content routing is an incredibly complex problem. You've heard about the DHT a little bit earlier


2
00:00:11,920 --> 00:00:16,640
and some of the optimizations that we're working on there from Gi, and also you've heard about


3
00:00:16,640 --> 00:00:25,160
this IPNI solution that you couldn't be blamed for recognizing our extremely disparate approaches


4
00:00:25,160 --> 00:00:33,000
to kind of solving this problem that doesn't exist in traditional location-based networks.


5
00:00:33,000 --> 00:00:40,120
And so I'd like to refer to this quote from Richard Feynman from an interview that he did,


6
00:00:40,120 --> 00:00:45,160
basically the idea being, there's such a lot in the world, there's so much distance between


7
00:00:45,160 --> 00:00:52,040
the fundamental rules of everything that the final phenomenon that results is actually


8
00:00:52,040 --> 00:01:00,200
just astoundingly hard to connect to the simple operations that actually result in that end outcome.


9
00:01:00,200 --> 00:01:07,720
And content routing is very much like that. We have a very, very complex set of networks


10
00:01:07,720 --> 00:01:16,280
with the need to look up these content identifiers, and the way that we do that seems very complicated


11
00:01:16,280 --> 00:01:22,920
because there's so many ways to look at it, but truly it's actually a very, very simple operation


12
00:01:22,920 --> 00:01:32,440
that's just happening at a very large scale. And so what is the IPFS Content Routing Workgroup?


13
00:01:32,440 --> 00:01:41,080
We're kind of a dialogue-driven focal point for discussing these problems and looking at both


14
00:01:41,080 --> 00:01:47,720
simultaneously the immediate execution of all of these things that we've talked about today,


15
00:01:47,720 --> 00:01:55,640
getting these out into potentially Kubo or addressing content routing discussions for


16
00:01:55,640 --> 00:02:02,760
DHT optimizations, delegated content routing, API design, all of these immediate executions


17
00:02:02,760 --> 00:02:08,600
that are ongoing. And then simultaneously we're addressing this future problem of


18
00:02:08,600 --> 00:02:16,760
how do we get to this federated network of indexer nodes, interplanetary network indexer nodes,


19
00:02:16,760 --> 00:02:25,000
which results in a decentralized solution to what is a highly centralized immediate


20
00:02:25,000 --> 00:02:30,680
kind of result that we're working on. So we're the place to talk about these things.


21
00:02:30,680 --> 00:02:38,600
Who makes up this content routing workgroup presently? So I've kind of got a group of folks


22
00:02:38,600 --> 00:02:44,920
here that are consistent contributors to it. It's the IPNI team, the IPFS stewards,


23
00:02:46,040 --> 00:02:53,560
ProbeLab, and the Bifrost team who does a lot of testing support for us, but also who enables us


24
00:02:53,560 --> 00:02:59,000
to actually roll a lot of these changes out or test them in the Kubo nodes or their clusters.


25
00:02:59,000 --> 00:03:06,360
And then we occasionally have guests that visit from IRO, the general public, or just generally


26
00:03:06,360 --> 00:03:12,200
like independent contributors that are interested from the IPFS side of the house. But ultimately,


27
00:03:12,200 --> 00:03:17,960
these meetings are actually open to the public. They're all recorded on YouTube. So if you'd like


28
00:03:17,960 --> 00:03:23,560
to go back through historical ones and kind of see the things that we've discussed or understand


29
00:03:23,560 --> 00:03:29,320
a little bit of context and how we approach these problems, you can go back and recreate all those


30
00:03:29,320 --> 00:03:37,880
discussions as well as all of our notes, which are shared publicly on Notion. So why should you care?


31
00:03:37,880 --> 00:03:45,080
And what is the current state of content routing today as we discuss it? I think Mossi's already


32
00:03:45,080 --> 00:03:50,760
really covered a lot of that in his earlier talk, but I'll just kind of recapture that just for


33
00:03:50,760 --> 00:03:59,400
context here. We've got the DHT, which is old reliable. It's chugging along, and you can count


34
00:03:59,400 --> 00:04:05,720
on it to persistently be there and do what it's intended to do. We can always rely on it. This is


35
00:04:05,720 --> 00:04:11,880
one content routing system that provides a peer-to-peer functionality. The HydroBoosters


36
00:04:11,880 --> 00:04:17,640
still exist presently. They're operating as a bridging function right now, so they're passing


37
00:04:17,640 --> 00:04:24,440
content. And then you've got the Interplanetary Network Indexer, which exists as a standalone


38
00:04:24,440 --> 00:04:32,280
instance, SID.contact, which you can refer to. But additionally, there are actually seven of


39
00:04:32,280 --> 00:04:37,080
these instances running globally. I'll show you a map in a little bit, which highlights where


40
00:04:37,080 --> 00:04:43,800
those actually physically are right now, that you could theoretically refer to to be performing


41
00:04:43,800 --> 00:04:53,080
lookups. So they are available. I look forward for the SID.contact instance of the


42
00:04:53,080 --> 00:04:58,840
Interplanetary Network Indexer. We're presently working immediately on our double-hash value


43
00:04:58,840 --> 00:05:04,520
store, so we're going to get an in-depth look at that with Yvonne's talk a little bit later today.


44
00:05:04,520 --> 00:05:10,280
Something we're really excited about, this presents a use case for privacy that we'll actually be


45
00:05:10,280 --> 00:05:17,320
able to obscure a bit. What exactly people are doing on our network, we don't want that to be


46
00:05:17,320 --> 00:05:24,120
necessarily externally visible. We want people to have the option to choose whether or not they


47
00:05:24,680 --> 00:05:32,920
want their traffic essentially monitored. And we've got some monitoring of index operator


48
00:05:32,920 --> 00:05:37,800
instances. So I mentioned these six other instances that are publicly available.


49
00:05:37,800 --> 00:05:44,280
Right now, they're all going through the process independently of synchronizing the ad chain that


50
00:05:44,280 --> 00:05:53,320
we use to provide lookups at SID.contact. So all of these indexer instances are currently at varying


51
00:05:53,320 --> 00:05:58,760
states of the ingestion process. Some of them are very close behind us, and some of them are


52
00:05:58,760 --> 00:06:04,840
further away. But I wouldn't blame any of you for not knowing what the state of any of those is,


53
00:06:04,840 --> 00:06:09,400
because we're not advertising that to the broader community. You can't see what the state of


54
00:06:09,400 --> 00:06:15,400
synchronization is across these instances. And so a next big step for us as we approach this


55
00:06:15,400 --> 00:06:21,640
longer-term goal of having a federated, distributed mesh of network indexers that you could refer to


56
00:06:21,640 --> 00:06:28,200
for lookups is to understand exactly what the state of all these are. And then only then could


57
00:06:28,200 --> 00:06:37,080
we actually approach solving these problems of weighting or reliability or what the different


58
00:06:37,080 --> 00:06:42,520
responses are that you might get from one of these. And then additionally, we're working on this


59
00:06:43,080 --> 00:06:49,080
edge node service. Masi mentioned the caching problem. The idea that the closer we can get


60
00:06:49,960 --> 00:06:56,600
a reflection of this index, this key value store that we present for you to be able to perform


61
00:06:56,600 --> 00:07:05,560
lookups, the faster those lookups might be. And so we have the Saturn network. The CDN is


62
00:07:06,600 --> 00:07:13,400
really broad. It's a deep network. And we have the opportunity to deploy an edge node service


63
00:07:13,400 --> 00:07:19,800
to that network and take advantage of the fact that we have this highly distributed network to


64
00:07:19,800 --> 00:07:26,760
get lookups as close as possible to reduce network traffic across this entire network.


65
00:07:27,800 --> 00:07:36,040
And then so what does this look like? That's the IPNI in relation to this broader, more disparate


66
00:07:36,040 --> 00:07:46,680
problem of content routing. Content routing crosses several teams. And so we've got, I mentioned


67
00:07:46,680 --> 00:07:54,760
ProbeLab, Bifrost, the IPFS stewards. But really, the problems that we're solving actually affect


68
00:07:54,760 --> 00:07:59,480
almost everybody. Everybody that's using the network is impacted by the decisions that are


69
00:07:59,480 --> 00:08:05,640
being made during these discussions of the content routing process. So some of the closer


70
00:08:05,640 --> 00:08:11,960
term stuff, I think Guy mentioned he's working on this DHT refactoring. Maybe a broader way to look


71
00:08:11,960 --> 00:08:18,120
at that is the optimizations of the DHT, because you also heard Masi kind of discuss a little bit


72
00:08:18,120 --> 00:08:23,320
of optimizing the speed and the efficiency with which the IPNI can leverage the DHT.


73
00:08:24,200 --> 00:08:29,400
There's a broader conclusion there that if we take all of these sources and we're able to optimize


74
00:08:29,400 --> 00:08:35,880
them, that ultimately we can leverage the DHT even better than the way that we do now.


75
00:08:35,880 --> 00:08:41,320
There's also the concept of delegated content routing puts. So another thing you might have


76
00:08:41,320 --> 00:08:50,200
heard Masi mention was that we've highly optimized this pathway for ingestion. But ultimately,


77
00:08:50,200 --> 00:08:55,080
we really want to get to the point where we can delegate the function of putting information


78
00:08:55,720 --> 00:09:02,680
into the system. And so that's work associated with that that we would like to address as a group.


79
00:09:02,680 --> 00:09:09,160
And then there's BitSwap provider search delays and peer routing optimization.


80
00:09:09,720 --> 00:09:16,440
There are other opportunities that have nothing necessarily immediately to do with the IPNI,


81
00:09:16,440 --> 00:09:20,280
but ultimately result in a better content routing experience across the network.


82
00:09:21,080 --> 00:09:25,000
These are the types of discussions that you're going to find happening in this content routing


83
00:09:25,000 --> 00:09:29,640
workgroup. And then ultimately, kind of at the tail end of this, the direction that we're


84
00:09:29,640 --> 00:09:35,960
really going as a group with all of these teams is that we want ambient discovery of


85
00:09:35,960 --> 00:09:43,080
these indexer instances so that we have this federated network of indexers that exists to


86
00:09:43,080 --> 00:09:47,160
serve the purpose of the whole network so that you always consistently have a place to


87
00:09:47,960 --> 00:09:52,360
very speedily and efficiently look up information anywhere on the network.


88
00:09:52,360 --> 00:10:01,560
So what does it look like right now? These are actually the instances of the IPNI


89
00:10:01,560 --> 00:10:08,360
that are running. They're all in different states, as I mentioned. So we have a very heavy presence


90
00:10:08,360 --> 00:10:15,960
here in North America. Probably it's good. But really, ultimately, what we want is we want this


91
00:10:15,960 --> 00:10:23,640
map to be broken down into zones that service the lookup frequency. And so we will be making a very


92
00:10:23,640 --> 00:10:30,840
intentional push to find folks that are interested in operating an indexer instance in South America,


93
00:10:30,840 --> 00:10:35,640
Africa, the Middle East, Europe, so that we have more representation closer to where the lookups


94
00:10:35,640 --> 00:10:43,320
happen, as well as we have both Australia, which we recently added. We're very excited about that.


95
00:10:43,320 --> 00:10:49,640
They're actually pretty close to ingesting the ad chain. And then our friends in China here.


96
00:10:53,240 --> 00:11:00,120
So what kind of discussions can you expect to find in the content routing workgroup in the future?


97
00:11:00,120 --> 00:11:05,640
This is my pitch to you to actually potentially join this workgroup, listen in, contribute your


98
00:11:05,640 --> 00:11:13,960
ideas. I think the elephant in the room that I would point out is that when you take the


99
00:11:13,960 --> 00:11:20,600
decentralized nature of the DHT and this concept of pure routing, when you look at something like


100
00:11:20,600 --> 00:11:25,960
the interplanetary network indexer, the immediate conclusion that you're likely to come to is that


101
00:11:25,960 --> 00:11:32,360
one of these is a highly centralized lookup solution in relation to a highly decentralized,


102
00:11:32,360 --> 00:11:40,600
kind of independently operated solution. And so we have a goal of trying to get this now very fast,


103
00:11:40,600 --> 00:11:48,120
very highly scalable solution to be decentralized and to take those values that were used in the


104
00:11:48,120 --> 00:11:55,160
implementation of the DHT and spread them out into this solution that is highly adaptable and


105
00:11:55,160 --> 00:12:01,400
extensible and can be potentially evolved into even further content routing methods in the future


106
00:12:01,400 --> 00:12:06,680
that we haven't even imagined yet. So there are a few things that in the immediate future will


107
00:12:06,680 --> 00:12:12,280
contribute towards that discussion. We've got index operator discussions and feedback.


108
00:12:12,280 --> 00:12:18,520
So we have all these folks running IP and I instances right now. We need to build those


109
00:12:18,520 --> 00:12:24,040
relationships in a way where we're able to start handling traffic with them, that we figure out


110
00:12:24,040 --> 00:12:31,640
what our incentive solutions are going to be to justify them running these instances. I'm sure


111
00:12:32,200 --> 00:12:36,680
everybody's doing everything out of the kindness of their own heart, but ultimately there's some


112
00:12:36,680 --> 00:12:42,840
traffic involved with this and the good of the network alone may not drive these behaviors as


113
00:12:42,840 --> 00:12:48,360
much as we might like it to. So there are some incentive solutions that need to be discussed,


114
00:12:48,360 --> 00:12:54,520
designed and worked out, and how we ultimately achieve this. Juan did a talk last year at IPFS


115
00:12:54,520 --> 00:13:01,080
Thing. I highly recommend looking at where he discussed potentially like L2 or L1 solutions


116
00:13:01,080 --> 00:13:06,680
to this type of problem, but we're at a point in time where we're basically setting the stage


117
00:13:07,720 --> 00:13:14,600
for that design discussion to result in an actually distributed mesh network of these instances.


118
00:13:14,600 --> 00:13:23,560
And then we've got Rhea and Lassie ultimately as a kind of a potential staging ground for a lot of


119
00:13:23,560 --> 00:13:29,240
the work that we're doing. So we now have this super powerful tool available to us to try things


120
00:13:29,240 --> 00:13:33,800
out. And so when the group's meeting, we're kind of talking about these things that we can


121
00:13:33,800 --> 00:13:40,680
potentially do. And then I kind of put down these client agnostic interfaces, but I think Guy brought


122
00:13:40,680 --> 00:13:45,800
a really important solution to the group recently to talk about looking at our interfaces and how we


123
00:13:46,760 --> 00:13:51,560
deal with like Reprovide, for instance. There's a lot of discussion that's going to be happening,


124
00:13:51,560 --> 00:13:59,880
I think, around that in the near term future. And then I just want to say again, this is a sales


125
00:13:59,880 --> 00:14:05,240
pitch. We really want to encourage your participation in this group, at least in the Slack.


126
00:14:05,240 --> 00:14:10,200
But if you join the calls, we'd be happy to have you there as well. I put some links in this


127
00:14:10,200 --> 00:14:15,320
presentation to share with you. There's a Luma that has all the future discussions that are coming up.


128
00:14:15,320 --> 00:14:19,720
I hear in about two weeks will be the next one. There's a YouTube channel with our playlist,


129
00:14:19,720 --> 00:14:25,240
which includes all of the historic discussions that you're welcome to join. And then additionally,


130
00:14:25,880 --> 00:14:30,360
the notion for the content routing work group has an aggregation of all the information,


131
00:14:30,360 --> 00:14:36,440
decisions we're making, discussions we're having on this topic. You're welcome to go look around


132
00:14:36,440 --> 00:14:41,880
in there. And then ultimately, if you join our Slack IPFS content routing work group or message


133
00:14:41,880 --> 00:14:47,480
me directly, I would absolutely be happy to talk to you about any of this stuff that we're working on


134
00:14:48,760 --> 00:14:52,360
and future solutions for this whole problem.


135
00:14:52,360 --> 00:15:04,760
Can you walk through the process of how a deal or a SID gets advertised on the network?


136
00:15:04,760 --> 00:15:14,040
And I know you were calling for people to be running these indexer nodes to cache these


137
00:15:14,040 --> 00:15:20,360
associations between SIDs and where they exist on the network. Are there frameworks in place


138
00:15:20,360 --> 00:15:26,120
that I don't have to cache the entirety of the network or I can just cache SIDs that I'm


139
00:15:26,120 --> 00:15:32,920
interested in from maybe a certain agent or deal maker or from a certain provider?


140
00:15:33,800 --> 00:15:42,200
It's a pretty good question. If you think about the way a SID ends up in the key value store


141
00:15:42,200 --> 00:15:49,240
on the network indexer, you have to right now run a provider instance. And that provider instance


142
00:15:49,240 --> 00:15:56,840
usually is happening in the case of Boost or it's happening on the networks in Filecoin.


143
00:15:57,400 --> 00:16:02,840
As part of the dealmaking process, that SID gets announced as an advertisement


144
00:16:02,840 --> 00:16:08,120
to the network indexer. And so there's actually some metadata associated with it beyond just the


145
00:16:08,120 --> 00:16:13,960
key value pair of the SID and the provider ID, but that's what we represent, the end result,


146
00:16:13,960 --> 00:16:21,720
to be able to perform lookups. The idea of delegating puts as a content routing,


147
00:16:22,680 --> 00:16:27,480
that's the idea of creating an API that's an interface that potentially you could


148
00:16:28,360 --> 00:16:35,480
perform these advertisements through an HTTP payload, for instance. And so that's part of


149
00:16:35,480 --> 00:16:42,920
the process that we're working towards is how do we disaggregate these solutions that we have to


150
00:16:42,920 --> 00:16:49,960
get your content onto the network indexer. And so in the future, it should be much easier to do.


151
00:16:50,760 --> 00:16:58,360
Another work stream that we're approaching right now is, and we need a lot of help from


152
00:16:58,360 --> 00:17:06,680
our partners on the IPFS side of the house, is to ultimately get IPFS nodes to potentially,


153
00:17:06,680 --> 00:17:13,400
or some iteration of IPFS nodes to be able to perform these advertisements explicitly on their


154
00:17:13,400 --> 00:17:21,320
own without necessarily needing to run a provider instance independently. And so this is a work


155
00:17:21,320 --> 00:17:27,720
stream that is not presently underway, I would say, but it's in the design decision process where


156
00:17:27,720 --> 00:17:34,440
we're talking about ways that we might go about this. And then another, I would say, novel approach


157
00:17:34,440 --> 00:17:41,960
that you can take, so just kind of a few layers potentially, is through the eIPFS implementation.


158
00:17:42,840 --> 00:17:52,280
Just by virtue of leveraging that specific eIPFS version, you can advertise through that method.


159
00:17:52,280 --> 00:18:01,080
So that is actually how the folks at NFT Storage and Web3.storage are presently announcing their


160
00:18:01,080 --> 00:18:06,600
IPFS additions to the network to the indexer. Did that answer your question?


161
00:18:14,600 --> 00:18:20,920
Are you looking at anything in the FVM to help implement some of this? Because this sounds very


162
00:18:20,920 --> 00:18:30,600
similar to subgraphs in ETH. And I don't know how, off the top of my head, I don't really know


163
00:18:30,600 --> 00:18:39,320
I don't really have a good idea of how well it would scale to log SIDs in FVM logs. But is that


164
00:18:39,320 --> 00:18:44,760
like something you're thinking about? I won't pontificate on that. It's not immediately in


165
00:18:44,760 --> 00:18:51,240
the zone of discussion topics. We're actually, I would say, pretty heavily iterating on immediate


166
00:18:51,240 --> 00:18:57,880
problems with content routing. However, these types of ideas are really great. And I think


167
00:18:57,880 --> 00:19:03,800
FVM is very fresh. Join the content routing workgroup and come and discuss these topics


168
00:19:03,800 --> 00:19:14,600
with us. You know we'd love to have you, Ben. Hannah. Hypothetically, if I were someone who was


169
00:19:15,320 --> 00:19:22,360
not fully bought into the IP&I approach, I maybe were a group that was researching how to do the


170
00:19:22,360 --> 00:19:28,280
DHT better. Would I still be someone who should show up at the content routing group?


171
00:19:28,280 --> 00:19:37,080
Yeah. You're the perfect person. This is exactly who we want to join this workgroup. I will say


172
00:19:37,080 --> 00:19:49,480
that the IP&I is a solution which ultimately gets us much closer to some state where potentially we


173
00:19:49,480 --> 00:19:57,720
can have a, like Masi said several times, smash Web 2.0 performance. We are making tradeoffs


174
00:19:57,720 --> 00:20:22,680
in the process of attempting to do that.


175
00:20:00,000 --> 00:20:27,700
we recognize that we're making those tradeoffs. We're doing it to get to an immediate state where we can get that performance in place and then disaggregate the problem of how do we decentralize now that we're able to do the thing, how do we deal with this very critical topic of representing our values through decentralized services and also obviously privacy is a big function of that. But we want that.


176
00:20:27,700 --> 00:20:36,400
Contention to result in actual action. And so you would find yourself in very good company.


177
00:20:36,400 --> 00:20:58,400
If I had a great algorithm. Which I don't. That's okay. That's okay. I mean, like the process of these discussions ultimately often is to design said algorithms by virtue of kind of the community discussion and to lead to those actions. And so your voice would be very appreciated. Absolutely.


178
00:20:58,400 --> 00:21:23,400
I wanted to add two things to two other questions that was mentioned. So the first one, Torfin mentioned that we're looking for other people to run network indexers. I wanted to make it absolutely clear that this is not an all or nothing protocol. You can absolutely run a network indexer that only indexes your stuff. That is perfectly welcome.


179
00:21:23,400 --> 00:21:51,400
On the provider side, in IP and IP protocol, you always store the information that you only provide. Which is the slight distinction to make there. For me, two words to highlight in that title is just content routing. And I wanted to connect it to the intro slides, which is this concept of content routing. We have some idea of the boundaries, but it is still loosely defined.


180
00:21:51,400 --> 00:22:15,400
What's there that unites us is the easiest way by which you can discover information and make it discoverable. And that is a value that is independent of protocol. And success for me would be a future where that is made true and the protocol or implementation becomes irrelevant to the end user.


181
00:22:15,400 --> 00:22:35,400
That's why this working group exists. So please don't let the three letters of IP and I scare you. This is not IP and I. IP and I is not necessarily the future. It's just a implementation of a routing system and hopefully many, many more. I hope that makes sense.


182
00:22:35,400 --> 00:23:03,400
Thanks, Masi. I was thinking more about what you said about if people can run indexers that don't have copies of everything, then as a client, you're going to need to know which indexer to talk to to find a particular piece of data. How is that any different from conceptually from location addressing? You have to know who to talk to in order to find the data that you're looking for.


183
00:23:03,400 --> 00:23:23,400
The short answer is I don't know. There's a lot of similarities for sure. I think the first thing to enable is to just make the content easier to discover. We haven't even touched this discoverer discovery problem.


184
00:23:23,400 --> 00:23:42,400
We have scratched the surface. There is a draft design by Will sitting in the back, ambient discovery stuff. This is something that we absolutely need to solve. It is slightly different in the case of IP and I because of the way it works.


185
00:23:42,400 --> 00:24:10,400
I totally see multiple discovery mechanisms through the DHT to then pass you on into nodes that then have the content. The fundamental idea there is that you play into the heterogeneity of the nodes where you have nodes that have more resources, are willing to do more for whatever benefit, and the rest of it is just figuring out how it's going to work together.


186
00:24:10,400 --> 00:24:26,400
That is different from the purist view of the DHT, which is everybody's flat, nobody's more important than anybody else. That's fantastic for resilience, but there's just more different use cases.


187
00:24:26,400 --> 00:24:40,400
It occurs to me that there is room for alternative solutions to then satisfy the different use cases. The trick, of course, is to make it all work together.


188
00:24:40,400 --> 00:24:58,400
I think the double hashing stuff is a great intro into making sure that all the systems actually do work together because we do not want to break routing from DHT to IP and I as a result of making it more private. To me, that is a really great exercise to make sure we've got the interfaces right.


189
00:24:58,400 --> 00:25:05,400
I know there are talks later on about what the interfaces are going to look like. It's the beginning.


190
00:25:05,400 --> 00:25:18,400
I think there's also, with content addressable data, we have all these unique possible outcomes where we can get outside of our heads a little bit.


191
00:25:18,400 --> 00:25:37,400
There's definitely a huge parallel, and I wouldn't blame you for recognizing it, with location-based addressing, typical networking, IP routing. But we also have all these functionalities available to us that aren't available in traditional IP-based routing.


192
00:25:37,400 --> 00:25:52,400
I think what we continue to explore in the future is where are the places where we can displace those traditional limitations of location-based networking, and what are these new paradigms that we can uncover and discover?


193
00:25:52,400 --> 00:26:04,400
I think these are the really exciting topics that we get to have in the content routing workgroup and through the discussions will surface. It feels like there's a lot of opportunities.


194
00:26:04,400 --> 00:26:18,400
I wanted to be clear that I'm not criticizing. I actually like location addressing. That's the thing that enables scalability. It's basically like sharding and stuff like that.


195
00:26:18,400 --> 00:26:23,400
Learning how to deal with it, I think, is an important problem.


196
00:26:23,400 --> 00:26:25,400
I'm with you there.


197
00:26:25,400 --> 00:26:43,400
Thank you. My understanding, I get why IPNS makes sense for large sets of CIDs, but also I think the DHT makes a lot of sense when it's a small set of CIDs.


198
00:26:43,400 --> 00:26:56,400
Say it's an IoT network or it's a private network, but also discovering the IPNS providers, IPNI providers that could be done through DHT.


199
00:26:56,400 --> 00:27:01,400
My understanding is we're not dropping the DHT, but just adding something else, right?


200
00:27:01,400 --> 00:27:14,400
Yeah, we want, ultimately, for the benefits of a distributed network like we have, we want accessible content routing methods to exist.


201
00:27:14,400 --> 00:27:21,400
We want people to explore this concept of content routing, potentially even think of solutions that we're not immediately having.


202
00:27:21,400 --> 00:27:34,400
But with the volume and scale of Filecoin, we're not at 1.3 trillion CIDs anymore. We're ingesting 30 to 40 billion a week right now.


203
00:27:34,400 --> 00:27:38,400
I'm persistently looking at these numbers in between talks, even.


204
00:27:38,400 --> 00:27:43,400
We actually are at 1.4 trillion right now, probably creeping up on 1.5.


205
00:27:43,400 --> 00:27:49,400
The rate of ingestion that's happening right now is massive. The network's massive.


206
00:27:49,400 --> 00:27:53,400
We expect that that's only going to continue to take off.


207
00:27:53,400 --> 00:28:01,400
The solution, the strategy that we're taking here is let's get this fundamental system in place which can handle this type of scale.


208
00:28:01,400 --> 00:28:06,400
We have to leverage a semi-centralized solution to do that.


209
00:28:06,400 --> 00:28:11,400
But then we approach all these other methods should operate in parallel.


210
00:28:11,400 --> 00:28:20,400
Solutions can come along that are completely, potentially contradictory in their solution to this problem that plug right into the network.


211
00:28:20,400 --> 00:28:24,400
But we're offering a solution in place.


212
00:28:24,400 --> 00:28:27,400
Maybe even leverage both.


213
00:28:27,400 --> 00:28:28,400
Oh, yeah.


214
00:28:28,400 --> 00:28:39,400
Like use the DHT to find the IP and AI providers and then use the IP and AI providers to find CRDs in, let's say, Filecoin or something like that.


215
00:28:39,400 --> 00:28:43,400
There's absolutely a world where these systems are entirely complementary.


216
00:28:43,400 --> 00:28:44,400
Yeah.


217
00:28:44,400 --> 00:28:45,400
Cool.


218
00:28:45,400 --> 00:28:47,400
I'll be haunting you in that work group.


219
00:28:47,400 --> 00:28:48,400
Join us.


220
00:28:48,400 --> 00:28:49,400
Yeah.


221
00:28:49,400 --> 00:28:50,400
Yeah.


222
00:28:50,400 --> 00:29:11,400
I think at the same time that we imagine, and there is this reality of many different content routing things, that there also are user desires where end product systems are going to move towards the latency in order to compete with Web 2 and so forth.


223
00:29:11,400 --> 00:29:29,400
And so there is a pretty strong push that we'll get from applications that resists these cascade-like things and having the location service or the I'm going to have my index of my own content.


224
00:29:29,400 --> 00:29:42,400
Where I think in the same way that we've seen with cassette currently, it leads to then decisions of are we waiting for that, and those things will end up as lower tiers if nothing else.


225
00:29:42,400 --> 00:29:56,400
So there is this pushback towards, you know, how much can you get where you push it left, I think was the metaphor that Masi used earlier, into the immediate systems that users are querying.


226
00:29:56,400 --> 00:29:59,400
And so I think there's a couple things there.


227
00:29:59,400 --> 00:30:22,400
One is if you're running instances of or an instance of IPNI, one of the things that IPNI is doing for you is making car archives of the processed index and so forth, such that it becomes easier to share that and push it left to other instances rather than just having your own content routed thing.


228
00:30:22,400 --> 00:30:26,400
Although you get that now very quickly within your domain.


229
00:30:26,400 --> 00:30:34,400
But it lowers the barrier, hopefully, for that becoming just part of the broader network.


230
00:30:34,400 --> 00:30:58,400
And so I guess I'm still hoping that we don't end up with lots of location addressed subnetworks, but rather can design systems that allow for the true content addressing where stuff is that is going to be public, where a user that wants it is close to them.


231
00:30:58,400 --> 00:31:06,400
And that you don't have to go back to a growing and unbounded number of potential providers.


232
00:31:06,400 --> 00:31:08,400
Thanks, Will.


233
00:31:08,400 --> 00:31:10,400
This is a really important point.


234
00:31:10,400 --> 00:31:15,400
And this is something that we will deliberate on continuously in this workgroup.


235
00:31:15,400 --> 00:31:21,400
That's what this workgroup exists for, is to have these types of discussions and to define the pathways that we take.


236
00:31:21,400 --> 00:31:22,400
All right.


237
00:31:22,400 --> 00:31:23,400
Well, thank you, everybody, for listening to me talk.


238
00:31:23,400 --> 00:31:28,400
Thank you.
